IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 61, 2023

5919212

Memory Optimization in RNN-Based Full
Waveform Inversion Using Boundary
Saving Wavefield Reconstruction
Shaowen Wang , Graduate Student Member, IEEE, Yong Jiang, Peng Song , Jun Tan ,
Zhaolun Liu, and Bingshou He
Abstract‚Äî In wave equation modeling, wavefields propagating
over time can be regarded as feedforward in a recurrent neural
network (RNN). Therefore, the seismic inversion problem based
on partial differential wave equations can be addressed using
automatic differentiation in the state-of-the-art deep learning
frameworks, eliminating the need for explicit backpropagating
the residual wavefield. However, one challenge that arises in the
context of automatic differentiation is the significant memory
usage due to the necessity of storing the hidden states of the RNN
(i.e., wavefields in seismic modeling) during forward computation
for constructing the computational graph and computing the
derivatives during backpropagation. This memory overhead can
become a bottleneck, particularly when dealing with large-scale
inversion problems. To mitigate this issue, we propose an effective
boundary-saving strategy that allows for the reconstruction of
the computational graph during the backpropagation process.
Instead of storing all the intermediate wavefields at each time
step, we selectively save the necessary information at the boundaries, thereby significantly reducing the memory footprint. This
approach enables us to maintain the convenience and efficiency
of automatic differentiation computations while minimizing the
memory requirements. Both 2-D and 3-D numerical experiments
validate the accurate reconstruction of wavefields with minimal
loss in precision, while the computational graph is simultaneously reconstructed. Consequently, the gradients can also be
calculated correctly by automatic differentiation with minimal
CPU/graphics processing unit (GPU) memory occupation.
Index Terms‚Äî Automatic differentiation, boundary saving, full
waveform inversion.

F

I. I NTRODUCTION
ULL waveform inversion (FWI) aims to find a highresolution representation of the subsurface by iteratively

Manuscript received 8 August 2023; revised 27 August 2023; accepted
16 September 2023. Date of publication 20 September 2023; date of current
version 4 October 2023. This work was supported in part by Wenhai Program
of the ST fund of Laoshan Laboratory (LSKJ) under Grant LSKJ202204803,
in part by the National Natural Science Foundation of China under Grant
42074138, in part by the China National Offshore Oil Corporation (CNOOC)
under Grant CCL2023XHPS001EM, Grant KJGG-2022-0104, and Grant
CCL2022RCPS0513RCN, and in part by the Open Fund Project of No. 1
Geological Team of Shanong Provincial Bureau of Geology and Mineral
Resources under Grant 2022DY03. (Corresponding author: Peng Song.)
Shaowen Wang is with the College of Geoscience, Ocean University of
China, Qingdao 26600, China (e-mail: shaowinw@163.com).
Yong Jiang is with the CNOOC Ltd., Shanghai 200050, China (e-mail:
jiangyong@cnooc.com.cn).
Peng Song, Jun Tan, Zhaolun Liu, and Bingshou He are with the College of Geoscience, Ocean University of China, Qingdao 266100, China,
also with the Laoshan Laboratory, Qingdao 266200, China, and also with
the Key Laboratory of Submarine Geosciences and Prospecting Techniques
(Ministry of Education), Qingdao 266100, China (e-mail: pengs@ouc.edu.cn;
tanjun0532@ouc.edu.cn; zhaolun.liu@ouc.edu.cn; hebinshou@ouc.edu.cn).
Digital Object Identifier 10.1109/TGRS.2023.3317529

optimizing the model parameters until the modeled waveforms
best match the observed waveforms [1], [2]. To perform
waveform modeling using computers, particularly graphics
processing units (GPUs), subsurface models are typically
discretized using a grid representation. When applying a finite
difference time domain (FDTD) method to discrete the wave
equations, the partial differentiation of the wavefields with
respect to the spatial coordinates can be implemented by
convolving a kernel with the wavefield, which is a typical
technique employed in convolutional neural networks (CNN).
The temporal differencing scheme of the wave equation
enables the iterative update of the wavefield, just like the
hidden states updated in a recurrent neural network (RNN).
Consequently, the seismic forward modeling can be viewed
as wavefields propagating through RNN [3], [4], [5], [6].
When representing the forward modeling of wave equations
using an RNN, we can leverage the automatic differentiation
capabilities offered by state-of-the-art deep learning frameworks like PyTorch to implement FSI without the need for
explicit backpropagation of the adjoint source. The gradients
calculated by automatic differentiation are consistent with
the adjoint method [7]. In RNN-FWI, the velocity model
building in traditional FSI transformed to training the parameters of an RNN. The RNN-FWI framework can be easily
incorporated with other neural networks to use more complicated loss functions and regularizations for better inversion
results [8].
The grid models, such as compressional wave velocity (vp ),
shear wave velocity (vs ), and density are considered as
trainable parameters in the RNN-FWI framework. However,
in the pure (default) automatic differentiation mode, FWIRNN requires large GPU/CPU resources to store the hidden
states (i.e., the complete wavefields in FWI-RNN) for gradient calculations when backpropagating the loss between the
predicted data and the observed data [5]. It should be noted
that the advantages of FWI-RNN diminish when there are
multiple hidden states to store or when the wavefields are
large and require extensive storage capacity, particularly in 3-D
cases.
Boundary-saving strategies [9], [10], [11] have been widely
used in traditional seismic modeling algorithms based on
finite difference methods, such as reverse time migration (RTM) [12], [13] and FWI [14], [15]. These strategies
selectively save the necessary values of the wavefields
and reconstruct the whole snapshot during backpropagating,

1558-0644 ¬© 2023 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

5919212

Fig. 1.

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 61, 2023

RNN (a) and cell (b) of the forward RNN.

where the adjoint source is propagated to calculate the correlation of the adjoint wavefield and forward wavefield.
In this study, we first analyzed the feasibility of boundarysaving strategies in FWI-RNN. Then we provided a detailed
description of the effective boundary-saving-based automatic
differentiation and compared it with the pure version of
automatic differentiation. Finally, we show some results of the
proposed method in RNN-based acoustic FWI with two 2-D
benchmark models and a 3-D model.
II. M ETHOD
A. Forward Modeling
The second-order acoustic wave partial equation can be
written as:
‚àÇu (x)/‚àÇt = v(x) ‚àá u(x) + S(x0 , t0 )
2

2

2

2

(1)

where u is the pressure wavefield, x is spatial coordinates,
v(x) is the velocity field at location x, and S(x0 , t0 ) represents
the source excited at location x0 and time t0 .
Discretizing (1) using the finite difference method with a
second-order in time and 2N th-order in spatial scheme, we can
derive the following equation:
u t+1 (x) = v 2 (x)1t 2 u t (x) ‚àó k + 2u t (x) ‚àí u t‚àí1 (x) + S(x0 , t0 )
(2)
where the spatial derivatives are expressed as convolutions, ‚àó
is the convolutional operator, k is the convolutional kernel
with size (2N + 1) √ó (2N + 1) where 2N represents the
differential order and the values at the cross-directions in
k are the differential coefficients obtained from the Taylor
expansion.
In RNN, a cell represents the minimum computation unit
applied to the trainable parameters. The forward propagation
of the wavefields is same at each timestep, so a simpler version
of (2) can be formulated as:
ut+1 = cell(ut , ut‚àí1 , st ; m)

(3)

where cell(‚àó) means a basic unit of RNN and maintains hidden
states (i.e., u t ).

Fig. 1(a) shows the forward modeling RNN which takes
wavelets as inputs and outputs seismic records. Fig. 1(b) shows
a cell of (a) which calculates the right-hand of (2), st is the
source amplitude at each timestep and the wavefield ut+1 are
hidden states that stores knowledge that the RNN currently
holds, yt are the records at specified locations.
B. Pure Automatic Differentiation
The FWI tries to find a model that minimizes the discrepancy between the observed data and the predicted data which
is modeled by the current model parameters. The optimization
of the model parameters can be expressed as
arg min J (RNN(m, s; xr ), dobs (xr ))

(4)

m

where m is the model parameter (v p in acoustic case), J is
a scalar which is usually named objective function or loss
function, RNN represents the forward modeling operator, s is
the source function, xr is the locations of the receivers, and
dobs is the observed records.
Take the derivative of the objective function with respect
to the model parameters, we can obtain the back-propagation
equation as follows:
‚àÇJ
= backward(J )
‚àÇm

(5)

where backward(J ) means we need backward the loss calculated by objective function to compute the gradients of the
variables in the computational graph without calculating the
gradients of J w.r.t ut explicitly. It is the pure automatic
differentiation in the currently popular deep learning (DL)
frameworks, which allows users to perform FWI in a simpler way without manually defining adjoint propagations and
gradient formulas.
The gradients of the model parameters can be calculated by
the chain rule [6]

Nt 
X
‚àÇJ
‚àÇut
‚àÇJ
=
.
(6)
‚àÇm
‚àÇu
t
m ‚àÇm ut ‚Ä≤ Ã∏=t
t=1

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MEMORY OPTIMIZATION IN RNN-BASED FSI

Fig. 2.

5919212

Directed graph of FWI based on pure automatic differentiation.

Take the derivative of J with respect to the wavefield at
timestep t + 1
‚àÇJ
‚àÇJ
‚àÇ J ‚àÇut+1
‚àÇ J ‚àÇut+1
=
+
+
.
‚àÇut+1
‚àÇut+1
‚àÇut+1 ‚àÇut
‚àÇut+1 ‚àÇut‚àí1

(7)

Equations (6) and (7) show that the objective function
depends on all the ordered hidden states. When we backward
the loss J at timestep t + 1, the wavefields at previous times
must be available for calculating (6).
An unrolled FWI-RNN with pure automatic differentiation
is shown in Fig. 2. In the forward propagation, for the purpose
of building the computational graph, the wavefields at each
timestep are stored in CPU or GPU memory to facilitate the
construction of the computational graph. The computational
graph plays a crucial role in tracking and organizing the
flow of computations within the RNN. However, it is important to note that this process incurs a significant memory
overhead due to the storage of wavefields. During backward
propagation, the computational graph and stored wavefields
are used by the automatic differentiation mechanism (AD)
to compute and accumulate gradients by (6). It effectively
traces the dependence between the output (wavefields) and the
model parameters of the FWI-RNN, enabling the computation
of gradients for optimization. The solid and wide orange
line linked to the memory represents heavy memory usage
and input/output (IO).
C. Effective Boundary Saving-Based Automatic
Differentiation
Actually, by using the effective boundary-saving strategy
discussed by Yang et al. [10], wave propagation can be
reversible under certain initial and boundary conditions, which
can be expressed as

(8)
urt‚àí1 = cell urt+1 , urt , st‚àí1 ; m, bt‚àí1
where b is the wavefield boundaries at timestep t ‚àí 1 and urt‚àí1
represents the reconstructed wavefield at t ‚àí 1. Besides, the
last two wavefields are also necessary as the initial condition:
urN t‚àí2 = cell(u N t‚àí1 , u N t , s N t‚àí2 ; m, b N t‚àí2 ).
In Fig. 3, the blue zone I is the absorbing boundary zone
for eliminating the boundary reflections, the gray zone II is
the effective boundary zone with width as N (where 2N
is the differential order of the Taylor expansion), and the

Fig. 3. Illustration of the effective boundary saving. (I) Absorbing boundary
zone, (II) effective boundary zone, and (III) wavefield update zone.

orange zone III is the wavefield update zone whose data will
be updated by the wave equation. In other words, instead
of storing all the wavefields (the whole area in Fig. 3) and
building the computational graph in the forward modeling,
we only need to save the effective boundaries (the gray zone
in Fig. 3) and the last two wavefield snapshots. Using the
last two wavefield snapshots as initial conditions and effective boundaries as the boundary conditions of each timestep,
we can propagate the wavefields in the reverse-time direction
and rebuild the computational graph, and then backward the
reconstructed wavefield by using automatic differentiation.
The directed graph of the effective boundary saving-based
automatic differentiation described earlier is shown in Fig. 4.
An extra modeling is needed in the loss function backward
propagation. The computational direction of this modeling is
in the reverse-time direction, aligning with the direction of the
loss back propagating. A snapshot of the computational graph
at each timestep is rebuilt for calculating and accumulating the
gradients. So, it is actually a trade-off between computation
and storage, where computations are performed on-the-fly
instead of explicitly storing the whole wavefield calculated
in the forward propagation. The dashed and slim orange line
linked to the memory represents lower memory usage and IO
compared with Fig. 2.
Fig. 5 illustrates the pseudocodes for the two methods
mentioned above. In pure automatic differentiation, gradient calculation is enabled during the forward modeling for
building the computational graph. However, in boundarysaving-based automatic differentiation, gradient calculation

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

5919212

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 61, 2023

Fig. 4.

Directed graph of FWI based on effective boundary saving-based automatic differentiation.

Fig. 5.

Pseudo-code of the pure automatic differentiation (Algorithm1) and effective boundary saving based automatic differentiation (Algorithm2).

should be disabled during forward modeling, and boundary
values should be saved. During loss backpropagation, gradient
calculation is enabled, values of boundaries are assigned to
the reconstructed wavefields, and gradients are computed and
accumulated at each time step. In Algorithm 1, we perform
a direct backpropagation of the scalar value of the objective
function. However, in Algorithm 2, we necessitate the use
of additional application programming interfaces (APIs) to
compute the gradient of the wavefield at timestep t ‚àí 1 with
respect to the leaves within the computational graph.
III. N UMERICAL E XAMPLES
In our examples, the spatial differentiation order is set to
2N = 2, so only one layer of the boundaries is needed to
store for reconstruction. In all our examples, an AMD EPYC
7543 32-Core CPU and a NVIDIA A40 (48 GB) GPU are
used for tests. Pytorch is used for implementing the modeling

and inversion tests. All the examples are running on GPU for
acceleration.
A dynamic source encoding strategy [16] is performed
to accelerate the computation of FWI. For multiscale inversion [16], data from six frequency bands with dominant
frequencies of 1, 3, 5, 8, and 10 Hz, and the full frequency
band data are used to gradually obtain the final velocity model.
We perform 100 iterations at each scale, with 20 randomly
encoded shots in a batch. An Adam optimizer with initial step
size of 5 and a decay rate of 0.75 for each scale is utilized for
optimization. A mean squared error (L2) objective function is
used for matching the predicted and observed data.
We use the following evaluation metrics for quantitative
analysis. The first one is a model error, which is defined as the
mean squared error of the true model and the inverted model
errork =

‚à•mtrue ‚àí mk ‚à•2
size(m)

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

(9)

WANG et al.: MEMORY OPTIMIZATION IN RNN-BASED FSI

5919212

where mtrue is the ground truth model and mk is the inverted
model of the kth epoch. size(m) means the number of grid
points in the model.
The coding loss, which is defined as the mean square error
between the predicted and filtered observed data in a batch:
lossk =

2
Ik


X

B yipred (mk ) ‚àí B diobs

(10)

i

where yipred (mk ) is the ith predicted records at the kth epoch
with the model mk , Ik is the randomly subsampled shots at the
current epoch, and B(‚àó) is a filter applied to original observed
data with the current frequency band.
The memory saving ratio, which is defined as the difference
between the memory usage of the pure automatic differentiation (PAD) method and the effective boundary saving-based
automatic differentiation (EBS-AD) method, is divided by the
memory usage of the AD method.
Ô£±

Ô£¥
M = MPAD ‚àí MEBS-AD MEBS-AD
Ô£¥
Ô£¥
Ô£¥
k
Ô£¥
Y
Ô£¥
Ô£¥
Ô£¥
M
=
sizeof(dtype)
¬∑
N
t
¬∑
ni
Ô£¥
PAD
Ô£≤
i=1
(11)
Ô£¥
MEBS-AD = sizeof(dtype) ¬∑ N t
Ô£¥
Ô£¥
"
#
Ô£¥
k
k
Ô£¥
Y
Y
Ô£¥
Ô£¥
Ô£¥
¬∑
n
‚àí
(n i ‚àí 2N )
Ô£¥
i
Ô£≥
i=1

Fig. 6.

Marmousi model. (a) Ground truth model and (b) initial model.

i=1

where n i represents the size of the ith dimension; k represents
the dimensions of the model, and sizeof(dtype) is the size of
the data type used to store each value (in bytes). The default
value is 4 in our examples, which corresponds to a 32-bit
floating-point number. N t is the number of timesteps and 2N
is the spatial differential order.
A. Marmousi Model (2-D Case)
The Marmousi model with a width of 9.2 km and depth
of 3.5 km is used in this example. The spatial step of the
model is d x = dz = 10 m, and the sampling rate is 1 ms.
A total of 90 shots, spaced at an interval of 100 m, are modeled
for inversion. A Ricker wavelet with a dominant frequency
of 15 Hz is employed as the source function. The receivers
are evenly placed at the bottom of the sea, with a spacing
of 10 m. A 1-D model is used as the start model for FWI.
The ground truth and initial Marmousi velocity models are
shown in Fig. 6(a) and (b), respectively.
Fig. 7(a) and (b) depict the gradients obtained at the
first epoch of the PAD and EBS-AD methods, respectively.
Fig. 7(c) illustrates the difference between the gradients shown
in Fig. 7(a) and (b). The non-zero difference between the
two gradients can be attributed to numerical errors that
arise between the reconstructed wavefield and the original
wavefield. However, the magnitude of the error is small,
resulting in minimal impact on the inversion results. It is
worth noting that since the first frequency band has a dominant
frequency of 1 Hz, so the gradient only captures large-scale
(low wavenumber) information of the model.
Fig. 8 shows the final velocity models obtained through
FWI using PAD and EBS-AD, respectively. Both methods

Fig. 7. Gradients of Marmousi model at the first epoch. (a) Automatic
differentiation, (b) effective boundary saving, and (c) the difference between
(a) and (b).

successfully generate highly accurate velocity models, even
when utilizing a 1-D model as the initial start.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

5919212

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 61, 2023

Fig. 8. Final velocity models obtained by using pure automatic differentiation
(a), and effective boundary saving-based automatic differentiation (b).

Fig. 9. Differences between the true and the inverted models using: (a) pure
automatic differentiation and (b) effective boundary saving-based automatic
differentiation.

The difference between the ground-truth model and the
inverted models using these two methods is shown in Fig. 9.
The differences highlight that the accuracy in the shallow
region is significantly higher compared to the deeper portion.
Moreover, while the velocities within layers are inverted
accurately, the interfaces remain somewhat indistinct. Using
a denser grid with broader frequency data could potentially
address this issue.
Fig. 10 shows trace comparisons at distances of 4.0, 6.0,
and 8.0 km, respectively. The inverted velocity curves closely
resemble the ground-truth model. The difference between

Fig. 10. Velocity profile comparison of the true velocity model (black),
initial model (green), pure automatic differentiation inverted model (red),
and effective boundary saving-based automatic differentiation inverted model
(blue) at (a) x = 4.0 km, (b) x = 6.0 km, and (c) x = 8.0 km.

velocities obtained through the EBS-AD-based FWI and
PAD-based FWI is minimal, as they appear to be almost overlapped. However, some sharp interfaces and deep structures
with high velocities are not accurately recovered.
Fig. 11(a) and (b) shows model errors and losses of the
two methods. A sudden change in the curvature of the
curve indicates a shift in the frequency band of multiscales.
The results demonstrate that boundary saving strategy does not
compromise the accuracy of the inversion; it achieves nearly
the same level of accuracy as pure automatic differentiation.
To implement effective boundary saving, we need to
recalculate the wavefields by (8) and assign boundaries to
the wavefield. However, PAD simply extracts the wavefields

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MEMORY OPTIMIZATION IN RNN-BASED FSI

5919212

Fig. 12. 2-D overthrust model. (a) Ground truth model and (b) initial model.

Fig. 11. Model error curve (a) and loss (b) of the inversion based on pure
automatic differentiation (red) and effective boundary saving-based automatic
differentiation (blue).
TABLE I
C OMPARISON OF THE PAD AND EBS-AD BASED ON M ARMOUSI M ODEL

from memory, resulting in higher computational efficiency
compared to the EBS-AD approach. Specifically, for one
epoch, PAD needs 4.5 s while EBS-AD takes 7.9 s as shown
in Table I. The PAD method utilizes 5924 MB of storage
to hold the complete wavefield, while the EBS-AD method
achieves the same with a significantly smaller storage requirement of just 45 MB, mainly by storing the boundaries. The
EBS-AD saves 99.2% memory compared to the PAD method.
B. Overthrust Model (2-D Case)
A 2-D overthrust model with a width of 12.5 km and a
depth of 4 km is used for testing purposes. The grid size is
25 √ó 25 m. The sampling rate is 2 ms, with a record length
of 4 s. In FWI, a total of 100 shots are employed, spaced at
intervals of 100 m. The receivers are placed at the surface of
the model, with intervals of 25 m. The ground-truth model
and the 1-D start model are shown in Fig. 12(a) and (b),
respectively.

Fig. 13. Gradients of overthrust model obtained at the first epoch. (a) Pure
automatic differentiation, (b) effective boundary saving-based automatic differentiation, and (c) the difference between (a) and (b).

The gradients obtained at the first epoch of the first
frequency band are depicted in Fig. 13. Specifically,
Fig. 13(a) and (b) illustrate the gradients obtained from the

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

5919212

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 61, 2023

Fig. 14. Final velocity models obtained by using pure automatic differentiation (a) and effective boundary saving-based automatic differentiation (b).

Fig. 15. Differences between the true and the inverted models using. (a) Pure
automatic differentiation and (b) effective boundary-saving-based automatic
differentiation.

Fig. 16. Velocity profile comparison of the true velocity model (black line),
initial model (green line), pure automatic differentiation inverted model (red
line), and effective boundary saving-based automatic differentiation inverted
model (blue line) at (a) x = 3.75 km, (b) x = 7.5 km, and (c) x = 11.25 km.

PAD and EBS-AD methods, respectively. The difference
between the two methods is presented in Fig. 13(c). There
is no significant difference between the two gradients, thereby
validating the effectiveness of the EBS for FWI within the
context of automatic differentiation.
The final inversion results of the PAD and EBS-AD methods
are shown in Fig. 14(a) and (b), respectively. It can be observed
that both methods have successfully reconstructed almost all
the structures compared with the ground truth model shown
in Fig. 14(a).
The difference between the ground truth model and
the inverted models of PAD and EBS-AD are shown in
Fig. 15(a) and (b), respectively.

Fig. 16 shows trace profiles at distances x = 3.75 km, x =
7.5 km, and x = 11.25 km for comparison. The inverted
models obtained through the PAD and EBS-AD methods
exhibit similarities to each other and both closely resemble
the true model.
The model error curves and the coding L2 loss curves are
shown in Fig. 17(a) and (b), respectively. In both subfigures,
the curves of the two methods overlap in the low-frequency
bands, but they separate at high frequency bands.
Table II presents a comparison between the PAD and
EBS-AD methods in terms of various metrics. The PAD
method achieved a final model error of 0.145 and a final loss

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MEMORY OPTIMIZATION IN RNN-BASED FSI

Fig. 17.
Model error curve (a) and loss (b) of the inversion based on
pure automatic differentiation (red line) and effective boundary saving-based
automatic differentiation (blue line).
TABLE II
C OMPARISON OF THE PAD AND EBS-AD BASED ON OVERTHRUST M ODEL

of 0.47, with a computational time of 2.0 s per epoch. On the
other hand, the EBS-AD method resulted in a slightly lower
final model error of 0.132, a slightly higher final loss of 0.49,
and a longer computational time of 3.9 s per epoch. The PAD
method employs 610 MB of storage for the entire wavefield,
whereas the EBS-AD method requires only 10 MB to store
the boundaries. It demonstrated a remarkable memory saving
of 98.35% compared with PAD method.
C. Modified Marmousi Model (3-D Case)
We generate a 3-D velocity model based on the 2-D
Marmousi2 model [17]. The width and the length of the
generated model are 2.5 km, and the depth is 1.25 km.
The grid size in the three dimensions is 12.5 m. A Ricker
wavelet with a 10 Hz dominant frequency is used as the
source. Fig. 18(a) shows slices at y = 0.25 km, y = 1.25 km,
and y = 2.25 km, respectively. Fig. 18(b) shows slices at
x = 0.25 km, x = 1.25 km, and x = 2.25 km, respectively.

5919212

Fig. 18.
Slices of the 3-D ground truth model. (a) Velocity slices at
y = 0.25 km, y = 1.25 km, and y = 2.25 km, respectively (from left to
right). (b) Velocity slices at x = 0.25 km, x = 1.25 km, and x = 2.25 km,
respectively (from right to left).

For the purpose of FWI, an initial linear model with a velocity
ranging from 1500 to 3200 m/s is adopted, which is illustrated
in Fig. 19. Just like the 2-D cases in Sections II-B and II-C,
we utilized 6 frequency bands for the multiscale strategy.
The number of sources and receivers are 100 and 400,
respectively, uniformly distributed on the x0y plane.
Fig. 20(a) and (b) shows the locations of the sources and
receivers, respectively.
Fig. 21 shows slices selected from the final EBS-AD
inverted 3-D model. The inverted model is similar to the
ground truth shown in Fig. 18, which validated the feasibility
of our proposed method in 3-D cases. In the 3-D case,
the PAD method encountered ‚Äúout of memory‚Äù because a
large amount of wavefields are needed to store. Therefore,
we only display the results of the EBA-AD inverted results.
The theoretical memory usage for storing the wavefields of the
PAD method is 46 698 MB and that of the EBA-AD method is
only 1831 MB.
Fig. 22 shows trace profiles at distance (x, y) = (1.25 km,
1.25 km) and (x, y) = (0.625 km, 0.625 km) for comparison.
The inverted models obtained through the EBS-AD method
closely approximates the actual values. The 3-D inversion
results may not be as favorable as those in 2-D (as shown
in Fig. 10), possibly due to the sparse distribution of receivers
since the grid cell of the receivers is 250 √ó 250 m. Employing
a denser arrangement of receivers should potentially lead to
an improved inversion result.
The model error curves and the coding L2 loss curves are
shown in Fig. 23(a) and (b), respectively. The convergence

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

5919212

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 61, 2023

Fig. 19. Slices of the linear start model. (a) Velocity slices at y = 0.25 km,
y = 1.25 km, and y = 2.25 km, respectively (from left to right). (b) Velocity
slices at x = 0.25 km, x = 1.25 km, and x = 2.25 km, respectively (from
right to left).

Fig. 20.

Fig. 21. Slices from the inverted model. (a) Velocity slices at y = 0.25 km,
y = 1.25 km, and y = 2.25 km, respectively (from left to right). (b) Velocity
slices at x = 0.25 km, x = 1.25 km, and x = 2.25 km, respectively (from
right to left).

Locations of (a) sources and (b) receivers.

of both model error and loss function indicates that the
boundary saving strategy can be effectively integrated into the
RNN-based 3-D full waveform inversion.
IV. D ISCUSSION
In the PAD method, the computational graph is established
during the forward simulation process. In contrast, within
the EBA-AD method, forward simulation serves the purpose
of storing boundary values for wavefield reconstruction, and
gradients are not computed at this stage. Therefore, a computational graph is not constructed, and the stored wavefields are
not detached from any graph.
When backpropagating the loss, we first enable gradient
computation, followed by the inverse time reconstruction

Fig. 22. Velocity profile comparison of the true velocity model (black line),
initial model (green line), and effective boundary saving-based automatic
differentiation inverted model (blue line) at (a) x = 1.25 km, y = 1.25 km
and (b) x = 0.625 km, y = 0.625 km.

of the wavefield, and then invoke the appropriate APIs to
compute the gradients. At this point, the computational graph
has been deactivated, allowing us to safely assign values to
the boundaries without affecting the gradient calculations.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

WANG et al.: MEMORY OPTIMIZATION IN RNN-BASED FSI

5919212

C ODE AVAILABILITY
The codes that support the findings of this study are openly
available at https://github.com/GeophyAI/seistorch.
R EFERENCES

Fig. 23. Model error curve (a) and loss (b) of the inversion based on effective
boundary saving-based automatic differentiation.

Therefore, if we aim to circumvent the impact of in-place operations on gradients, we need to devise a method that enables
in-place operations to occur outside the computational graph.
Implementing this in the acoustic case is straightforward, as it
requires only a single variable for boundary assignments.
The Conv2d/Conv3D APIs within deep learning frameworks
often support batch calculating, allowing us to concurrently
compute multiple shots to enhance the computational efficiency of classic FWI without source encoding. This avenue
also sets the stage for our forthcoming research endeavors.
V. C ONCLUSION
The PAD in DL framework needs large amount memory to
store hidden states of RNN (wavefield snapshots in seismic
inversion) for constructing the computational graph, out of
memory can arise when the model is very large. With effective boundary saving strategy-based automatic differentiation
(EBS-AD), we only need to store the wavefields at a thickness
equal to half of the difference order and rebuild the computational graph in the backward propagation. The trade-off
between computation and storage is important in RNN-based
seismic inversion since we always face large models. We performed acoustic inversion in the context of PAD and EBS-AD
by using Marmousi model (2-D), Overthrust model (2-D) and a
modified Marmousi2 model (3-D), respectively. Results show
that EBS-AD can perform RNN-based FWI with low-memory
usage and no loss in accuracy, albeit the cost of computational
efficiency. The boundary saving methods can also be used for
more intricate wave equations in the context of RNN and deeplearning frameworks.
ACKNOWLEDGMENT
The authors sincerely appreciate the assistance of Dr. Tang
from Medical University of Innsbruck for the help with the
programming.

[1] P. Lailly and J. Bednar, ‚ÄúThe seismic inverse problem as a sequence
of before stack migrations,‚Äù in Proc. Conf. Inverse Scattering-Theory
Appl., Philadelphia, PA, USA, 1983, pp. 206‚Äì220.
[2] A. Tarantola, ‚ÄúInversion of seismic reflection data in the acoustic
approximation,‚Äù Geophysics, vol. 49, no. 8, pp. 1259‚Äì1266, Aug. 1984,
doi: 10.1190/1.1441754.
[3] T. W. Hughes, I. A. D. Williamson, M. Minkov, and S. Fan, ‚ÄúWave
physics as an analog recurrent neural network,‚Äù Sci. Adv., vol. 5, no. 12,
Dec. 2019, Art. no. eaay6946, doi: 10.1126/sciadv.aay6946.
[4] W. Wang, G. A. McMechan, and J. Ma, ‚ÄúElastic isotropic and anisotropic
full-waveform inversions using automatic differentiation for gradient
calculations in a framework of recurrent neural networks,‚Äù Geophysics,
vol. 86, no. 6, pp. R795‚ÄìR810, Nov. 2021, doi: 10.1190/geo2020-0542.1.
[5] J. Sun, Z. Niu, K. A. Innanen, J. Li, and D. O. Trad, ‚ÄúA theoryguided deep-learning formulation and optimization of seismic waveform
inversion,‚Äù Geophysics, vol. 85, no. 2, pp. R87‚ÄìR99, Mar. 2020, doi:
10.1190/geo2019-0138.1.
[6] A. Richardson, ‚ÄúSeismic full-waveform inversion using deep learning
tools and techniques,‚Äù 2018, arXiv:1801.07232.
[7] R.-E. Plessix, ‚ÄúA review of the adjoint-state method for computing
the gradient of a functional with geophysical applications,‚Äù Geophys.
J. Int., vol. 167, no. 2, pp. 495‚Äì503, Nov. 2006, doi: 10.1111/j.1365246X.2006.02978.x.
[8] J. Sun, K. Innanen, T. Zhang, and D. Trad, ‚ÄúImplicit seismic full
waveform inversion with deep neural representation,‚Äù J. Geophys. Res.,
Solid Earth, vol. 128, no. 3, Mar. 2023, Art. no. e2022JB025964, doi:
10.1029/2022JB025964.
[9] E. Dussaud et al., ‚ÄúComputational strategies for reverse-time migration,‚Äù
in Proc. SEG Tech. Program Expanded Abstr., Jan. 2008, pp. 2267‚Äì2271,
doi: 10.1190/1.3059336.
[10] P. Yang, J. Gao, and B. Wang, ‚ÄúRTM using effective boundary saving:
A staggered grid GPU implementation,‚Äù Comput. Geosci., vol. 68,
pp. 64‚Äì72, Jul. 2014, doi: 10.1016/j.cageo.2014.04.004.
[11] R. G. Clapp. (2009). Reverse Time Migration? Saving the Boundaries.
[Online]. Available: https://api.semanticscholar.org/CorpusID:55466322
[12] Y. Wang et al., ‚ÄúCuQ-RTM: A CUDA-based code package for stable and
efficient Q-compensated reverse time migration,‚Äù Geophysics, vol. 84,
no. 1, pp. F1‚ÄìF15, Jan. 2019, doi: 10.1190/geo2017-0624.1.
[13] Q. Zhang, W. Mao, and Y. Chen, ‚ÄúAttenuating crosstalk noise
of simultaneous-source least-squares reverse time migration with
GPU-based excitation amplitude imaging condition,‚Äù IEEE Trans.
Geosci. Remote Sens., vol. 57, no. 1, pp. 587‚Äì597, Jan. 2019, doi:
10.1109/TGRS.2018.2858850.
[14] N. Masmoudi and T. Alkhalifah, ‚ÄúFull-waveform inversion in acoustic
orthorhombic media and application to a north sea data set,‚Äù Geophysics,
vol. 83, no. 5, pp. C179‚ÄìC193, Sep. 2018, doi: 10.1190/geo2017-0738.1.
[15] P. Yang, J. Gao, and B. Wang, ‚ÄúA graphics processing unit implementation of time-domain full-waveform inversion,‚Äù Geophysics, vol. 80,
no. 3, pp. F31‚ÄìF39, May 2015, doi: 10.1190/geo2014-0283.1.
[16] G. T. Schuster, X. Wang, Y. Huang, W. Dai, and C. Boonyasiriwat, ‚ÄúTheory of multisource crosstalk reduction by phase-encoded statics: Theory
of multisource crosstalk reduction,‚Äù Geophys. J. Int., vol. 184, no. 3,
pp. 1289‚Äì1303, Mar. 2011, doi: 10.1111/j.1365-246X.2010.04906.x.
[17] G. S. Martin, R. Wiley, and K. J. Marfurt, ‚ÄúMarmousi2: An elastic
upgrade for Marmousi,‚Äù Lead. Edge, vol. 25, no. 2, pp. 156‚Äì166,
Feb. 2006, doi: 10.1190/1.2172306.

Shaowen Wang (Graduate Student Member, IEEE)
received the B.E. degree in exploration technology
and engineering from Shandong University of Science and Technology, Shandong, China, in 2018.
He is currently pursuing the Ph.D. degree in
marine geophysics with Ocean University of China,
Qingdao, China.
His research interests include seismic data denoising, seismic inversion, and deep learning.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

5919212

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 61, 2023

Yong Jiang received the B.E. and M.E. degrees
from Ocean university of China, Qingdao, China,
in 2003 and 2006, respectively.
He currently serves as the Deputy Manager of the
Exploration Department at CNOOC (China) Ltd.,
Shanghai, China. His research interests include seismic data interpretation, full waveform inversion, and
deep learning.

Zhaolun Liu received the Ph.D. degree in Earth
science and engineering from King Abdullah University of Science and Technology (KAUST),
Thuwal, Saudi Arabia, in 2019.
He is an Associate Professor at the College of Marine Geosciences, Ocean University of
China, Qingdao, China. He previously served as a
Post-Doctoral Research Associate at the Department
of Geosciences, Princeton University, Princeton, NJ,
USA. His research interests include source-encoded
acoustic-elastic coupled FWI and its application to
the onshore and offshore seismic data, seismic data processing and migration
based on machine learning methods, and surface-wave inversion and migration.

Peng Song received the B.S., M.E., and Ph.D.
degrees from Ocean university of China, Qingdao,
China, in 2002, 2005, and 2014, respectively.
He is a Full Professor with the College of
Marine Geosciences, Ocean University of China. His
research interests include deep learning, seismic data
processing, seismic forward modeling, migration,
and inversion.

Jun Tan received the B.S., M.E., and Ph.D. degrees
from Ocean University of China, Qingdao, China,
in 2005, 2008, and 2011, respectively.
He is an Associate Professor with the College of
Marine Geosciences, Ocean University of China. His
research interests include multiple attenuation, deep
learning, and seismic data processing.

Bingshou He received the B.S. and M.E. degrees
from China University of Mining and Technology,
Xuzhou, China, in 1996 and 1999, respectively,
and the Ph.D. degree from China University of
Petroleum (Beijing), Beijing, China, in 2002.
He is a Full Professor with the College of Marine
Geosciences, Ocean University of China, Qingdao,
China. His research interests include deep learning and seismic multicomponents data processing,
migration, and inversion.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on August 24,2024 at 16:16:05 UTC from IEEE Xplore. Restrictions apply.

