Downloaded 06/16/20 to 130.238.7.40. Redistribution subject to SEG license or copyright; see Terms of Use at http://library.seg.org/

Physics informed neural networks for velocity inversion

Yiran Xu1,2, Jingye Li1, Xiaohong Chen1
1
State Key Laboratory of Petroleum Resources and Prospecting, China University of Petroleum, Beijing, 102249, China
2
Division of Applied Mathematics, Brown University, Providence, RI 02912, USA
Summary
In this abstract, a new neural network, physics-informed
neural networks (PINNs) (M. Raissi, 2019) are introduced
and implemented to solve the inversion problems of wave
equations. PINNs employ standard feedforward neural
networks (NNs) with the partial differential equations (PDEs)
explicitly encoded into the NN using automatic
differentiation, while the sum of the mean-squared error in
initial/boundary conditions is minimized with respect to the
NN parameters. Specifically, here we use this network
structure to produce an accurate velocity model from seismic
data. Our approach relies on training deep neural networks
that are extended to encode the acoustic wave equation. In
the first case, given analytical solution to an initial boundary
value problem (IBVP) to infer very accurately the velocity
parameter. In the second case, given seismic wavefield data
in space-time, we use several coupled deep neural networks
to infer vary accuracy the velocity field. After compared the
results with full waveform inversion (FWI), the promising
results for synthetic 2D data demonstrate a new way of using
seismic data to identify key structures in the subsurface from
machine learning approaches.
Introduction
Seismic inversion aims to reconstruct an Earth subsurface
model based on seismic measurements. Such a subsurface
model is quantitatively represented by spatially variable
physical parameters, and is extracted from seismic data by
solving an inverse problem (Wang, 2016). While inverse
problem is well understood, it often leads to cumbersome
numerical methods which generally work very differently
from human interpreters(Roth and Tarantola, 1994). Recent
advances in machine learning to new data analyzing have the
potential to revolutionize our understanding to of the
physical world in modern application areas such as image
recognition(Krizhevsky et al., 2012), neuroscience(Lake et
al.,
2015),
cognitive
science,
finance,
and
genomics(Alipanahi et al., 2015). In the recent research
about geophysics, the explosive growth of literatures
concentrates on the following aspects.
â€¢
â€¢
â€¢
â€¢
â€¢

Compressive sensing by feature learning
Structured dictionary learning for seismic data
Fault imaging in 3D seismic using machine
learning
Segmentation of shale SEM by machine learning
Deep learning prior models for full waveform
inversion (FWI)

Â© 2019 SEG
SEG International Exposition and 89th Annual Meeting

However, few articles use machine learning to explore the
inherent constitutive relations of seismic data. In other
words, less well studied is how to discover the underlying
physical laws expressed by partial differential equations
from scattered data collected in space and time.
In this work, inspired by recent development in physicsinformed deep learning, which take a different approach by
employing deep neural networks and leverage their wellknown capability as universal function approximation. We
focus on the construction of nonlinear regression models that
can uncover the dynamic dependencies in a given set of
spatio-temporal dataset. More specifically, for the acoustic
wave equation, using the seismic wavefield dataset, we
return a closed form model that can be subsequently used to
discover the parameters in the equations.
Formulation of the problem
In this work, we consider parametrized and nonlinear formed
acoustic wave equation case.
ğ‘¢"" + ğ‘¢$$ âˆ’ ğœ†ğ‘¢'' = ğ‘†(ğ’“, ğ‘¡), (ğ‘¥, ğ‘¦) âˆˆ ğ›º, ğ‘¡ âˆˆ [0, ğ‘‡]

(1)

Where ğ‘¢(ğ‘¥, ğ‘¦, ğ‘¡) denotes the acoustic pressure , ğœ† =
1; where ğ‘ is the wave velocity to be determined, ğ‘ (ğ’“, ğ‘¡)
ğ‘:
is the source term as a function of space and time, ğ›º is a
subset of ğ‘…> .
We define ğ‘“(ğ‘¡, ğ‘¥, ğ‘¦) to be given by the equation (1)
ğ‘“: = ğ‘¢"" + ğ‘¢$$ âˆ’ ğœ†ğ‘¢'' âˆ’ ğ‘†(ğ’“, ğ‘¡)

(2)

The parameters ğœ† of the wave equation as well as the
parameters of neural networks ğ‘“(ğ‘¡, ğ‘¥, ğ‘¦) can be trained by
minimizing the mean squared error loss
C

D

ğ‘€ğ‘†ğ¸: = E
D

C

D

E
D

ILC

ILC

:

FGğ‘¢Hğ‘¡ I , ğ‘¥ I , ğ‘¦ I J âˆ’ ğ‘¢I G K +
:

FGğ‘“Hğ‘¡ I , ğ‘¥ I , ğ‘¦ I JG K

(3)

To generate a high-resolution data set for this problem, we
have employed the time-domain explicit finite-difference
method based on minimizing the mixed ğ‘˜ (wavenumber)space domain function approximation (Wang et al., 2017).

10.1190/segam2019-3216823.1
Page 2584

Double click here to type your header

Downloaded 06/16/20 to 130.238.7.40. Redistribution subject to SEG license or copyright; see Terms of Use at http://library.seg.org/

Examples
2D IBVP with analytical solution
Our first example involves an initial boundary value
problems (IBVP) with two-dimensional wave equation.
The IBVP was solved over the circular domain given by
ğ¼ = {(ğ‘¥, ğ‘¦)|ğ‘¥ : + ğ‘¦ : â‰¤ 1} , and over the time interval t âˆˆ
[0,1]. The wave equation is given by
TU V
TU '

TU V

TU V

= ğ‘ : (TU" + TU$),

(4)

where c is the wave speed, taken to be 2, the above PDE is
subject to the Dirichlet boundary condition
u(ğ‘¥, y, t) = 0 , (ğ‘¥, ğ‘¦) âˆˆ ğœ•ğ¼

(5)

And initial conditions
u(ğ‘¥, y, t) = ğ½\ Fğœ†] ^ğ‘¥ : + ğ‘¦ : K (x, y) âˆˆ ğ¼
`a
`b

(ğ‘¥, ğ‘¦, 0) = 0

(x, y) âˆˆ ğ¼

(6)
(7)

ğ½\ (âˆ™) represent a Bessel function of the first kind,
(fC)g "

:h
ğ½\ (r) = âˆ‘j
,
hL\ (h!)U (:)

(8)

And Î»] represents the 4th zero of ğ½\ (âˆ™). The IBVP has the
analytical solution
ğ‘¢(ğ‘¥, ğ‘¦, ğ‘¡) = ğ½\ Fğœ†] ^ğ‘¥ : + ğ‘¦ : Kcos (ğ‘ğœ†] ğ‘¡).
The analytical solution to (4) are shown in Figure 1.

(9)

Figure 1. The analytical solution of IBVP.
2D acoustic wave equation with source term
This example aims to highlight the ability of our method to
handle acoustic wave equation. The acoustic wave equation
is a classical field equation that is used to study the P-wave
propagation in the medium. As shown in (1), we employ the
Ricker wavelet as source term, the center frequency is set
16Hz. In order to assess the accuracy of our method, we have
simulated (1) using explicit finite difference method with
spatial arbitrary even-order accuracy. The model size is
3ğ‘˜ğ‘š Ã— 6ğ‘˜ğ‘š with 10m gridding space.
Given numerical scattered wavefield ğ‘¢(ğ‘¡, ğ‘¥, ğ‘¦), our goal is
to identify the unknown parameters ğ‘£(ğ‘¥, ğ‘¦), for the complex
model, the velocity varies with spatial position. To
demonstrate the ability of our method to learn from scattered
training data, we have chosen ğ‘ = 500000, corresponding
to a mere 0.3% of the total available simulation data resulted
by the forward modeling. The neural network architecture
(as shown in Figure 2) used here consists of 8 layers with 20
neurons in each layer.
The velocity inverse process with PINNs is depicted in
Figure 3, it performs the inverse of the velocity model from
wavefield, in the realistic practice, itâ€™s hard to get the
ground-truth model, and the PINNs is designed to minimize
the difference between the inversed velocity model and
ground-truth one by optimizing the MSE loss function (3).
As shown in Figure 4, we test several layered models to
validate the ability of PINNs to inverse the velocity from
seismic data. After comparing with FWI results, we can see
the accuracy and flexibility of PINNs to build the velocity
model.
Table 1. Correct PDE along with the identified one
obtained by learning

1D IBVP
2D IBVP

True parameter

Identified parameter

ğ‘¢"" âˆ’ 0.25ğ‘¢'' = 0

ğ‘¢"" âˆ’ 0.24992ğ‘¢'' = 0

ğ‘¢"" + ğ‘¢$$ âˆ’ 0.25ğ‘¢'' = 0

ğ‘¢"" + ğ‘¢$$ âˆ’ 0.24986ğ‘¢'' = 0

Â© 2019 SEG
SEG International Exposition and 89th Annual Meeting

Relative Error
0.32%
0.56%

10.1190/segam2019-3216823.1
Page 2585

Downloaded 06/16/20 to 130.238.7.40. Redistribution subject to SEG license or copyright; see Terms of Use at http://library.seg.org/

Double click here to type your header

Figure 2. Acoustic wave informed neural networks: a plain vanilla densely connected neural network, with 8 hidden layers and
20 neurons per hidden layer per output variable, take the input variable ğ‘¡, ğ‘¥, ğ‘¦ and output ğ‘¢, as for the activation function, we use
ğœ(ğ‘¥) = tan(ğ‘¥). For illustration purpose only, the network depicted in this figure comprises three hidden layers and six neurons
per hidden layer. We employ automatic differentiation to obtain the required derivatives to compute the residual (physicsinformed) networks ğ‘“. The total loss function is composed of the regression loss of the wave pressure ğ‘¢ on the training data and
the loss imposed by the differential equations ğ‘“. Here, the differential operators ğœ•' , ğœ•" , and ğœ•$ are computed using automatic
differentiation and can be thought of as â€˜activation operatorsâ€™. Moreover, the gradients of the loss function are back-propagated
through the entire network to train the neural network parameters using the Adam optimizer.
model building by encoding acoustic wave equation and
discover the parameters. In this work, the data-driven
algorithm for the velocity inversion demonstrates the
capability of PINNs which encodes the underlying physical
laws. The comparison of results to FWI shows the accuracy
and reliability of our proposed method.

Figure 3. The inversion work flow, the new models are
predicted after optimized the loss function of PINNs.
Conclusions
Physics-informed neural networks (PINNs) consist of an
uniformed feedforward neural network and another network
induced by the physical law in the form of PDE. Here for the
first time we implement a PINNs to geophysical velocity

Â© 2019 SEG
SEG International Exposition and 89th Annual Meeting

The future work forward to two main directions: switch the
input data to seismic record rather than the wavefield
snapshots, this deficiency also limits our application of this
method to real data. The second line of work must extend the
method to three-dimensional data, as for a machine learning
approach, which is mainly a scalability problem rather than
a fundamental one.
Acknowledgments
I give my gratitude to the financial support of China
Scholarship Council (CSC). This research is based on the
opensource from Mr. Maziar Raissi on GitHub
(https://github.com/maziarraissi

10.1190/segam2019-3216823.1
Page 2586

Ground truth (Real velocity models)

FWI

PINNs

Updated Velocity Model

5000

5000

4900

4900

5000

4900

10

100

10
4800

4800

4800

20
4700

4600

30

4500

4400

4700

4700

200

30

4600

4600

40

4500

Depth (m)

20

300

4500

4400

50

40

4400

400

4300

4300

4300

60
4200

50

4100

4200

4200

500

70
4100

4100

60

4000

20

40

60

80

100

120

80

4000

20

40

60

80

100

120

140

160

600

4000

200

400

600

800

1000

1200

Distance (m)
Updated Velocity Model
4500

4500

4500

10
10

4000

100

4000

4000

20
20

3500

30

3000

200

3500

30

40

3000

Depth (m)

Downloaded 06/16/20 to 130.238.7.40. Redistribution subject to SEG license or copyright; see Terms of Use at http://library.seg.org/

Double click here to type your header

3500

300

3000

50
40

2500

2500

400

2500

60
50

2000

60

1500

20

40

60

80

100

120

2000

70

80

140

1500

20

40

60

80

100

120

140

160

500

2000

600

180

1500

200

400

600

800

1000

1200

1400

Distance (m)

4500

4500

4400

4200

100

100

100

4000

200

3800

4000

4000

200

200

3600

300

3400

300

3500

3500

300

3200

400

400

400

3000
3000

3000

2800

500

500

500

2600

2400

600
50

100

150

2500

600

200

50

100

150

200

2500

600
50

100

150

200

Figure 4. The results methods showcase a series of promising results for a diverse collocation of velocity models. Here, we
compare these results predicted by the PINNs (right row) with FWI (middle row). The predicted model closely resembles the
ground truth in structure and velocity.

Â© 2019 SEG
SEG International Exposition and 89th Annual Meeting

10.1190/segam2019-3216823.1
Page 2587

Downloaded 06/16/20 to 130.238.7.40. Redistribution subject to SEG license or copyright; see Terms of Use at http://library.seg.org/

REFERENCES
Alipanahi, B., A. Delong, M. T. Weirauch, and B. J. Frey, 2015, Predicting the sequence specificities of DNA-and RNA-binding proteins by deep
learning: Nature Biotechnology, 33, 831â€“838, doi: https://doi.org/10.1038/nbt.3300.
Krizhevsky, A., I. Sutskever, and G. E. Hinton, 2012, Imagenet classification with deep convolutional neural networks: Advances in Neural Information Processing Systems.
Lake, B. M., W. Zaremba, R. Fergus, T. Gureckis, 2015, Deep neural networks predict category typicality ratings for images: Cognitive Science
Society.
Raissi, M., P. Perdikaris, and G. Em Karniadakis, 2017, Physics informed deep learning (part ii): Data-driven discovery of nonlinear partial differential
equations. arXiv preprint arXiv:1711.10566.
RÃ¶th, G., and A. Tarantola, 1994, Neural networks and inversion of seismic data: Journal of Geophysical Research: Solid Earth, 99, 6753â€“
6768.https://doi.org/10.1029/93JB01563
Wang, Y., 2016, Seismic inversion: Theory and applications: John Wiley and Sons.
Wang, Z., J. Li, B. Wang, Y. Xua, and X. Chena, 2018, A new central compact finite difference scheme with high spectral resolution for acoustic wave
equation: Journal of Computational Physics, 366, 191â€“206, doi: https://doi.org/10.1016/j.jcp.2018.03.030.

Â© 2019 SEG
SEG International Exposition and 89th Annual Meeting

10.1190/segam2019-3216823.1
Page 2588

