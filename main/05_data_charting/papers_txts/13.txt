See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/327612425

Velocity model building with a modiﬁed fully convolutional network
Conference Paper · August 2018
DOI: 10.1190/segam2018-2997566.1

CITATIONS

READS

67

1,483

3 authors:
Wenlong Wang

Fangshu Yang

Harbin Institute of Technology

Harbin Institute of Technology at Weihai

30 PUBLICATIONS 919 CITATIONS

17 PUBLICATIONS 693 CITATIONS

SEE PROFILE

Jianwei Ma
Peking University
200 PUBLICATIONS 6,304 CITATIONS
SEE PROFILE

All content following this page was uploaded by Fangshu Yang on 26 December 2018.
The user has requested enhancement of the downloaded file.

SEE PROFILE

Velocity model building with a modified fully convolutional network
Wenlong Wang, Fangshu Yang and Jianwei Ma, Harbin Institute of Technology
SUMMARY
We introduce a machine learning based method to estimate
the P-wave velocity models directly from the prestack seismic traces using a modified fully convolutional network. The
network is tuned to map multi-shot seismic traces to velocity
models. We train the network with pairs of synthetic velocity models and their corresponding multi-shot seismic traces
which are simulated from the velocity models with acoustic
wave equations. Multiple shots are used as channels in the network to increase data redundancy. The training process is expensive, but it only occurs once up front. The trained network
is then used to predict velocity models from testing seismic
traces, and it shows satisfactory prediction results. The cost
for predicting velocity models is negligible once the training is
complete.

In this paper, we work on the same problem of velocity model
building from prestack seismic traces, but we use a modified
fully convolutional network (FCN) (Long et al., 2015), which
has fewer parameters and thus is more efficient than DNNs.
Multiple shots can be easily cooperated as channels. The paper is organized as follows, we first introduce the architecture
of the network for velocity model building using seismic data.
Tests with synthetic data are then performed to compare the
results of the network trained with only 1 channel (1-shot network) and those trained with multiple channels (10-shot network). We show the improvements of training the network
with multiple shots as channels. To limit the scope of this paper, we focus on 2D isotropic acoustic models with a uniform
and constant density.

METHODOLOGY
INTRODUCTION
Velocity model building is an essential step in seismic exploration. Good velocity models are prerequisites for reverse time
migration (McMechan, 1983) and other seismic imaging techniques. The estimated velocity models can also be used as
initial models to recursively generate high resolution velocity
models with optimization algorithms (Tarantola, 1984). Common practices for generating velocity models include tomography and full-waveform inversion (FWI). However, both tomography and FWI are time-consuming, computationally expensive, and rely heavily on human interactions and quality
control.
Recent developments of machine learning (ML) technologies
provide the possibility to reduce or completely remove human
intervention from many formerly human-curated activities, for
example, image recognition, voice recognition and etc. Geophysicists may also be empowered with those new technologies, and seek possible applications in seismic data processing
routines to minimize human intervenes.
Many ML algorithms are built with artificial neural networks
(ANNs), which have a long history being used in geophysics.
However, most of the applications of ANNs focus on pattern
recognition in seismic attributes (Zeng, 2004; Zhao et al., 2015)
and faces classification in well logs (Lim, 2005; Hall, 2016). A
more challenging and interesting application is to input the network with prestack seismic traces and train the network to directly give geological interpretations of the subsurface. Early
pioneers who implement ANNs for velocity estimation include
Röth and Tarantola (1994) and Nath et al. (1999). In 2014,
Zhang et al. (2014) propose to use neural networks for automatic fault prediction from seismic traces. Araya-Polo ArayaPolo et al. (2018) build velocity models from seismic traces
with a deep neural network (DNN) and a feature extraction
step to reduce computational cost.

Velocity model building from seismic traces is challenging because it involves data transformation from seismic traces (x t) to the space/model domain (x - z), which poses as an inverse
problem. Neural networks are capable of approximating any
continuous function up to a specified accuracy (Hornick et al.,
1989), which provides the theoretical basis for this research.
FCN is a state-of-the-art network that performs pixel-wise semantic segmentation for images. It supplement a traditional
convolutional neural network (CNN) by successive upsampling
layers, thus the resolution of output is increased. A FCN usually consists of a series of convolutional units (convolution,
batch normalization and activation functions) and deconvolution layers for upsampling. The FCN architecture can also
be interpreted as a contracting path (encoder) and a expansive
path (decoder). Detailed descriptions of its components can be
found in Long et al. (2015).
To achieve velocity model building from seismic traces, we
made two major modifications to the FCN architecture (Figure 1). First, the original FCN is designed for image segmentation and reads input images in grey or RGB color channels,
while for processing seismic data, we assign different shot
gathers, which are recorded from sources at different locations
in the same model, as channels for the input. So the number
of channels for the input is the same as the number of sources
for each model. Thus, the multi-shot seismic data can be fed
into the network together to improve data redundancy. Second, different from an original FCN architecture, whose output
and input are in the same (image) domain and share the same
size. We utilize the encoder-decoder architecture of the FCN
to perform domain transformation from seismic data domain
(x - t) to the model domain (x - z). To handle the size discrepancy between inputs and outputs, we truncate the final output
layer to the size of the model before applying the loss function. The proposed network in Figure 1 is capable of training
itself during the contracting and expanding processes to map
the seismic data to the model domain.

64 64

128
128 128

256
256

512
512

512

1024

10 x 13

19 x 25

38 x 50

75 x 100

150 x 200

512

1024

512

128 128

64 64
1

256

512
150 x 80

256

256

1024
150 x 200

256

75 x 100

128

38 x 50

64

19 x 25

10

conv 3 x 3, Batch normalization and ReLU
max pool 2 x 2
up-conv 2 x 2
conv 1 x 1 and harvest

Figure 1: A modified FCN architecture for velocity model building using multi-shot seismic traces.

The loss function measures the distance between the prediction
and the ground truth (true velocity model). The loss function
that we use in the network is defined as the squared difference
(L2) between the ground truth velocity model V and the predicted velocity model Ṽ
1X
E=
[V (x) − Ṽ (x)]2 ,
(1)
N x
where N is the number of grid points in the model, and x indicates the pixel positions. The ground truth velocity models V
is given during the training process, but are hidden for testing
after the training. Note that the loss function is different from
that in a full wave inversion, in which the loss function measures the squared difference between observed and simulated
seismograms.
A popular variation of the FCN is called UNet (Ronneberger
et al., 2015). Characterized by a U-shaped network with the a
symmetric shape of a contracting path and an expansive path,
UNet is also equipped tunnels between the contracting and expansive layers [see Figure 1 in Ronneberger et al. (2015)] and
and demonstrates improved prediction accuracy with limited
training samples. A UNet architecture is built for automatic
salt detection (Wang et al., 2018), which is a classification
problem, with a cross-entropy loss function.

SYNTHETIC TESTS
In this section, we test the proposed algorithm with synthetic
data. We generate 1020 velocity models, and assign 1000 of
them as training samples, and the other 20 for testing. Each of
the models have 2, 3 or 4 layers as background velocity, and
the velocity of each layer ranges arbitrarily from 2500 to 3500
m/s with smooth interface curvatures and increases with depth.
A salt body with an arbitrary shape and position is embedded
into each of the models, and the salt bodies have a constant
velocity of 4500 m/s. All the models have the same size of x
× z = 150 × 80 grid points with spatial interval h = 10 m. We
use eighth-order in space and second-order in time finite differencing scheme to solve the acoustic wave equation with a
15 Hz Ricker wavelet. Convolutional perfectly matched layer
(CPML) absorbing boundary conditions (Komatitsch and Martin, 2007) are applied on all four grid edges to reduce unwanted
edge reflections.
For each model, 10 sources are evenly placed from (x, z) =
(0.2, 0.0) km to (1.3, 0.0) km and shot gathers are simulated

one after another. 150 receivers are evenly placed from (0.0,
0.7) km to (1.5, 0.7) km, which are at the bottom of the models, and form a top-bottom geometry. Signals recorded by this
geometry are mostly transmitted waves. Six sample models
(a) with a representative acquisition geometry and their corresponding seismograms (b) for training are plotted in Figure 2.
To validate the benefits of using multiple shots as channels for
input, we train the network with one channel (the fifth shot of
the 10) and 10 channels (10 shots) as input separately. Both
networks are trained with the 1000 training samples (pairs of
the shot gathers and velocity models), and the trainings are
terminated after 200 epochs.
The networks are trained on a workstation with one GFORCE
GTX 1080Ti GPU and 64 GB RAM. The generated seismic
traces and their corresponding true velocity models are used to
train the network with the stochastic gradient descent implementation of Pytorch (www.pytorch.org).
The computational time for training is proportional to the size
of the seismic traces and number of training samples, and it
is also related with the number of channels and the complexity of the network. In this paper, the training of the 1-shot
network took 1.4 hours to complete 200 epochs, and the training of 10-shot network took 3.2 hours. Once the trainings are
complete, it only takes a few seconds to apply the networks
to predict velocity models from seismic traces in the following testing process. Figure 3 shows the normalized losses, or
the L2 norm between the predicted velocity model and ground
truth decrease during the learning process. The 10-shot network converges faster than the 1-shot network.
To see the evolution of the network, 10 network snapshots are
captured during the training of the 10-shot network. We apply
those partially trained networks to one of the test samples (the
first velocity model in Figure 5a). The predicted velocity models using the 10 partially trained networks are shown in Figure 4 with their corresponding epoch status labelled at the bottom of each prediction. It shows that the network learns to fit
the low wavenumber components of velocity models at early
stages of the training, and gradually fits the high wavenumber
details in the velocity models as the training proceeds. This
process is similar to a multi-scale FWI approach, but the mechanism is different as no initial model nor wave equations need
to be provided to the artificial neural network.
The trained networks are then tested with the 20 test samples.

(a)

Position (km)
0.0

Position (km)
1.5

0.0

(b)

Position (km)

1.5

0.0

0.0

0.0

0.8

0.8

0.8

2.0

Depth (km)

0.0

1.5

0.0
Time (s)

4.5
velocity (km/s)

0.0

Position (km)
1.5

0.8

0.0

0.0

0.8

0.8

Figure 2: (a) Six representative models for training, and their corresponding geometry seismograms (10 shots are generated for
each model and only the fifth one is shown). The red dots indicate the source positions, and blue squares are receivers.

1.0

1 shot
10 shots

Position (km)

0.8
Normalized loss

0.0

Position (km)
1.5

0.0

1.5

0.0

0.6
0.4

0.8

0.2

Epoch = 10

Epoch = 30

Epoch = 50

Epoch = 70

0.0
0

25

50

75
100 125
Num. of epoch

150

175

200

0.8

Figure 3: The loss functions of 1-shot and 10-shot networks
decrease as the training proceeds.

To quantitatively analyze the accuracy of predictions, we choose
three horizontal positions x = 200 m, 600 m and 1100 m, respectively, and plot the 1-shot network predicted velocity values (red), 10-shot network predicted velocity values (green)
against the true velocity values (black) in velocity vs. depth
profiles (Figure 6). The 10-shot network gives better velocity
prediction than the 1-shot network. Considering the fact that
the loss functions of both 1-shot and 10-shot networks reach
the same level by the end of the training, it is reasonable to
assume the the 1-shot network is overfitted, and incorporating
more shots reduces the risk of overfitting.

4.5

Depth (km)

Six representative velocity models for testing are shown in Figure 5(a), and 10 shot gathers are generated for each model with
the same acquisition geometries as in the training set. The test
results of the 1-shot network are shown in Figure 5(b), and
the results of 10-shot network are shown in Figure 5(c). The
results show good approximations of the velocity models predicted directly from the seismic traces.

0.0

velocity (km/s)

0.0

0.8

2.0

Epoch = 90

Epoch = 110

Epoch = 130

Epoch = 150

Epoch = 170

Epoch = 190

0.0

0.8
0.0

0.8

Figure 4: The test results using partially trained network at
different epochs with 10 shots as input.

(a)

Position (km)
0.0

(b)

Position (km)
1.5

0.0

1.5

Position (km)

0.0

(c)

Position (km)
1.5

0.0

1.5

Position (km)

0.0

Position (km)
1.5

0.0

1.5

0.0

0.8
4.5

0.8

2.0

Depth (km)

velocity (km/s)

0.0

0.0

0.8

Figure 5: (a) Six representative velocity models for testing, and the corresponding predictions of 1-shot network (b) and 10-shot
network (c) during the test.

CONCLUSIONS

Velocity (m/s)
2000
4000

Velocity (m/s)
2000
4000

Velocity (m/s)
2000
4000
GT
1 shot PD
10 shots PD

0
100
200

Depth (m)

300
400
500
600

In this paper, we explore a data-driven technique that employs
a modified fully convolutional network to build velocity models directly from recorded seismic traces. Multiple shots are
learned as input channels to provide redundant information for
predicting the velocity model, and this scheme helps to reduce
this risk of overfitting. Once the network training is complete,
it is extremely fast to build velocity models with the trained
network and input seismic traces, and no human interventions
are involved. Because the loss function is measured in the
model domain, and no seismograms are generated when using
the network to predict velocity models, so there is no problem of cycle skipping. Network snapshots during the training shows that the low wavenumber component of the velocity
models are learnt first. The test results reach high accuracy
using synthetic data. Due to the limited number of training
samples and oversimplicitied synthetic models and data, applications to real seismic data are still difficult, and may require
a large database composed of real seismic traces and corresponding formerly interpreted velocity models for training the
network.

700
800

ACKNOWLEDGMENTS
(a) x = 200 m

(b) x = 600 m

(c) x = 1100 m

Figure 6: The predicted velocity models using 1-shot (red) and
10-shot (green) compared with the ground truth velocity model
(black) in velocity vs. depth profiles at three horizontal positions of the first test sample in Figure 6a. ”GT” represents
ground truth and ”PD” is prediction.

The research leading to this paper is supported by the Young
Talent Program (AUGA5710053217) from the Harbin Institute
of Technology.

REFERENCES
Araya-Polo, M., J. Jennings, A. Adler, and T. Dahlke, 2018,
Deep-learning tomography: The Leading Edge, 37, 58–66.
Hall, B., 2016, Facies classification using machine learning:
The Leading Edge, 35, 906–909.
Hornick, K., M. Stinchcombe, and H. White, 1989, Multilayer
feedforward networks are universal approximators: Neural
Networks, 2, no. 5, 359–366.
Komatitsch, D., and R. Martin, 2007, An unsplit convolutional
perfectly matched layer improved at grazing incidence for
the seismic wave equation: Geophysics, 72, no. 5, SM155–
SM167.
Lim, J. S., 2005, Reservoir properties determination using
fuzzy logic and neural networks from well data in offshore
Korea: Journal of Petroleum Science and Engineering, 49,
182–192.
Long, J., E. Shelhamer, and T. Darrell, 2015, Fully Convolutional Models for Smantic Segmentation: arXiv:1411.4038.
McMechan, G. A., 1983, Migration by extrapolation of timedependent boundary values: Geophysical Prospecting, 31,
no. 03, 413–420.
Nath, S. K., S. Chakroborty, S. K. Singh, and N. Ganguly,
1999, Velocity inversion in cross-hole seismic tomography by counterpropagation neural network, genetic algorithm and evolutionary programming techniques: Geophysical Journal International, 138, no. 01, 108–124.
Ronneberger, O., P. Fischer, and T. Brox, 2015, U-Net: Convolutional Networks for Biomedical Image Segmentation:
arXiv:1505.0459v1.
Röth, G., and A. Tarantola, 1994, Neural networks and inversion of seismic data: Journal of Geophysical Research, 99,
no. B4, 6753–6769.
Tarantola, A., 1984, Inversion of seismic reflecton data in the
acoustic approximation: Geophysics, 49, 1259–1266.
Wang, W., F. Yang, and J. Ma, 2018, Automatic salt detection
with machine learning: 80th Annual International Conference and Exhibition, Extended Abstracts, EAGE, submitted.
Zeng, H., 2004, Seismic geomorphology-based classification:
The Leading Edge, 23, 644–688.
Zhang, C., C. Frogner, M. Araya-Polo, and D. Hohl, 2014,
Machine-learning based automated fault detection in seismic traces: 76th Annual International Conference and Exhibition, Extended Abstracts, EAGE, 807–811.
Zhao, T., V. Jayaram, and K. J. Marfurt, 2015, A comparison
of classification techniques for seismic facies recognition:
Interpretation, 3, SAE29–SAE58.

View publication stats

