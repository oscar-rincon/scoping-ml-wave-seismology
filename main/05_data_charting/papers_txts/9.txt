IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 62, 2024

4507611

Seismic Wavefields Modeling With Variable
Horizontally Layered Velocity Models via
Velocity-Encoded PINN
Jingbo Zou , Cai Liu, Pengfei Zhao, and Chao Song

Abstract— Seismic modeling is crucial for tackling waveformbased inverse problems in geophysics. Physics-informed neural
networks (PINNs) have become a popular tool for simulating
seismic waves. Their ability to incorporate partial differential
equations (PDEs), initial conditions (ICs), and boundary conditions directly into the loss function allows for physically accurate
modeling. The prevalent approach in the current literature treats
the wave equation as a parametric PDE. However, the majority
of the existing studies simulate wavefields for a specific velocity
model, necessitating network retraining for different models,
thereby diminishing modeling efficiency. In response, we present
a velocity-encoded (VE) PINN (VE-PINN) that introduces feature
parameters to represent various layered velocity models, integrating them into the network. Drawing inspiration from supervised
learning, our approach employs a VE method to compute
initial wavefields for variable layered models. Remarkably, our
proposed VE-PINN demonstrates the ability to generalize across
different ICs within the dataset. This eliminates the need to
retrain the network for each new solution, offering significant
efficiency gains. Numerical results show that the VE-PINN
significantly enhances efficiency in solving the acoustic wave
equation for various layered velocity models compared with
finite-difference methods (FDMs). Subsequently, we extend the
application of our method to time-domain simulation for variable
source locations, demonstrating that the VE-PINN yields the
results that are consistent with numerical wavefields.
Index Terms— Physics-informed neural network (PINN), seismic modeling, variable velocity models, velocity-encoded (VE)
strategy.

I. I NTRODUCTION
EISMIC wave simulation relies on solving the wave
equation for a well-defined geological model, constituting
a fundamental component of full waveform inversion and
imaging. Numerical solutions to the wave equation predominantly employ methods, such as the finite-difference method
(FDM) [1], the finite-element method [2], and the spectral
element method [3]. Nevertheless, these conventional numerical methods require a mesh, which may cause numerical
dispersion when the mesh spacing is coarse, and also pose

S

a challenge when the domain has a complex shape, such as
topography.
The advancements in scientific computing have paved the
way for utilizing deep learning in developing numerical
solutions for PDEs. Neural networks, proven to be effective, are employed to approximate the intricate nonlinear
input–output relationships within complex systems [4]. In particular, Raissi et al. [5] proposed a physics-informed neural
network (PINN), which has received a lot of attention in many
scientific fields. PINN integrates PDEs into the loss function,
encompassing both initial and boundary conditions. This integration converts the task of solving PDEs into an optimization
problem. Operating as a mesh-free methodology, PINN simplifies meshing complexities and mitigates numerical dispersion.
Furthermore, it diminishes the necessity for extensive training
data, enhancing interpretability in comparison with traditional
data-driven deep learning methods. PINN finds applications
in diverse problem domains, such as chemistry [6], fluid
mechanics [7], material [8], and Earth systems [9]. In spite of
the accuracy and flexibility features of PINN solutions, solving
PDEs using PINNs is often expensive, especially for complex
solutions, such as wavefields [10]. Various strategies have been
proposed to enhance the performance of PINN. These include
fractional PINN (fPINN) [11] for fractional equations, parareal
PINN (PPINN) [12] designed to further enhance training
efficiency for long-time physical problems, variational PINN
(VPINN) [13] to reduce the order of differential operators,
and PINN with hard constraints (hPINN) [14] incorporating
hard constraints through the penalty method and augmented
Lagrangian method.
Recently, PINN is also applied to tackle the forward
and inverse problems in geophysics [40]. The foundational work by Waheed et al. [15] established a framework for solving the eikonal equation in isotropic media.
Subsequently, Waheed et al. [16] introduced transfer learning to accelerate convergence. Addressing the Helmholtz
equation, Alkhalifah et al. [10] proposed the simulation of
frequency-domain scattered wavefields as a means to avoid
the challenges associated with point-source singularities. This
approach was further extended to anisotropic media by Song
and Alkhalifah [17] and Song et al. [18]. To optimize the
training process, Song et al. [19] incorporated an adaptive
activation function, and Huang and Alkhalifah [20] enhanced
the network convergence and accuracy by using frequency
upscaling and neuron splitting. For multifrequency wavefields,

Manuscript received 19 December 2023; revised 4 March 2024 and 21 April
2024; accepted 17 May 2024. Date of publication 7 June 2024; date of current
version 20 June 2024. This work was supported in part by the National Key
Research and Development Program of China under Grant 2023YFC3707901
and in part by the National Natural Science Foundation of China under Grant
41874125. (Corresponding author: Chao Song.)
The authors are with the Department of Geophysics, College of
Geo-Exploration Science and Technology, Jilin University, Changchun,
Jilin 130026, China (e-mail: zoujb21@mails.jlu.edu.cn; liucai@jlu.edu.cn;
zhaopf@jlu.edu.cn; chaosong@jlu.edu.cn).
Digital Object Identifier 10.1109/TGRS.2024.3411472
1558-0644 © 2024 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.
See https://www.ieee.org/publications/rights/index.html for more information.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

4507611

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 62, 2024

Huang and Alkhalifah [21] introduced a novel loss function
utilizing a reference frequency, while Song and Wang [22]
developed a PINN framework with embedded Fourier features.
Seeking to capture nonsmooth features more effectively in
wavefields, Wu et al. [23] designed new neurons using a
quadratic function within the activation function and integrated
perfectly matched layer (PML) conditions into the loss function. In addition, Alkhalifah and Huang [24] utilized Gabor
functional solutions of the Helmholtz equation within PINNs,
which considerably helped convergence.
In the application of time-domain seismic wave simulation,
Moseley et al. [25], [26] proposed a “curriculum learning”
strategy to enhance training efficiency and scaled PINN to a
large computational domain known as the finite basis PINN
(FBPINN). In addition, Rasht-Behesht et al. [27] demonstrated
that PINN could simulate wave propagation and execute full
waveform inversion by leveraging numerical wave equation
solvers to provide wavefields as initial conditions (ICs).
Models incorporating continuous time-dependent point-source
functions, as exemplified by Alkhadhr and Almekkawy [28],
monitored the effects of the soft or hard constraints on
accuracy. Addressing the challenge of estimating velocity
and density without necessitating a good initial model,
Zhang et al. [29] devised a seismic inversion strategy encoding first-order acoustic wave equations, partially observed
seismograms, and well-logging data into the loss function.
Furthermore, Wang et al. [30] explored PINN for predicting
transcranial ultrasound wave propagation. By introducing an
absorbing boundary condition (ABC), Ren et al. [9] established a PINN model for solving elastic wave equations in
semi-infinite domains. To overcome training difficulties associated with PINN, Cheng Wong et al. [31] proposed sf-PINNs
with sinusoidal feature mapping appended to a typical PINN
with tanh activation in subsequent hidden layers. Recognizing
the hindrance posed by the multiterm objective function of
PINN, Nosrati and Emami Niri [32] suggested two main
modifications to the loss calculation: logarithmic and sigmoidal self-adaptive regularization multipliers. Zou et al. [33]
addressed the issue of balancing different terms in the loss
function by introducing a task-decomposed PINN (TD-PINN),
involving three training steps: pretraining, full learning, and
physics-enhanced training.
PINN has demonstrated success in solving wave equations. The current research predominantly employs wavefields
derived from conventional numerical methods (e.g., FDM
and finite-element method) as ICs. Nevertheless, a significant
challenge arises in efficiently transferring knowledge across
varied configurations. When treating the wave equation as
a parametric PDE with velocity as a variable parameter,
it becomes apparent that the majority of the aforementioned
methods are tailored and optimized for a specific velocity
model, rendering them incapable of predicting solutions for
another velocity model with training that may cost as much
as the original training. For the eikonal equation, Taufik
and Alkhalifah [34] suggested pretraining an autoencoder to
represent a velocity distribution in the latent space and then
used the latent representation of the velocity models as input
to train the PINNs for a distribution of velocity models.

However, the cost of such extended training is not cheap even
for solving the eikonal equation. In pursuit of constructing
a more direct solver that integrates variable velocity models
and source locations, we utilize continuous feature parameters,
such as velocity, layer interface, and point-source position as
inputs for the network.
Using PINNs as a foundation, we developed a framework
to perform seismic modeling with varying source locations
and velocity models. The notable contributions of this study
encompass the following.
1) To enhance the network’s generalization across diverse
velocity models, it is essential to include the velocity
variable v p as an input parameter within the system. In this study, drawing inspiration from supervised
learning, the training process contains two sequential steps: velocity-encoded (VE) wavefield predictor
and physics-guided seismic modeling. In the first part,
we incorporate wavefields corresponding to different
velocity models, computed using the FDM, into our
training dataset. Subsequently, a neural network, with
velocity models as inputs, is employed to generate initial
wavefields for a specific velocity model, which serve as
the ICs in the subsequent step. Our primary objective
is to establish a mapping between distinct velocity
models and their corresponding wavefields. Different
from the conventional data-driven methods, we only
use limited training data. In the physics-guided stage,
PINN is deployed to predict wavefield solutions for a
predetermined velocity model identical to the one in the
first step. Adhering to the constraints imposed by the
wave equation and ICs, PINN computes wavefields at
various time steps. The VE wavefield predictor furnishes
a more dependable foundation for initializing the PINN
parameters in the second step, enhancing the generalizability of the improved PINN.
2) In response to the direct incorporation of v p as an
input to the network, this study identifies and delves
into the challenges inherent in its practical implementation. Notably, simulations conducted in inhomogeneous
media are vulnerable to interfacial discontinuities,
thereby exerting a substantial influence on the accuracy
of network predictions. Building upon the framework
of PINN, we introduce a novel approach termed VEPINN. This research distinguishes between various
velocity models by incorporating feature parameters,
including interface depth and velocity in every layer.
The introduction of these feature parameters as inputs
in the initial step, labeled “VE wavefield predictor,”
enhances the network’s ability to capture velocity
variations and the corresponding characterization of
wavefields.
3) This method enables the direct simulation of timedomain wavefields for various source locations, simply
by using source location as an input. Neural networks, known for their aptitude in capturing nonlinear
relationships between continuous parameters and their
corresponding solutions, make this approach particularly effective. The underlying efficacy of this strategy

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

ZOU et al.: SEISMIC WAVEFIELDS MODELING WITH VARIABLE HORIZONTALLY LAYERED

stems from its fundamental principle, where continuous
parameters are utilized to represent information that
inherently possesses discontinuities. This study streamlines the workflow for modeling wave equations across
various velocity models and source locations. Once the
VE part of the network is trained, there is no necessity
to recalculate initial solutions using traditional numerical methods for different models. Multisource seismic
wave simulation using PINN has achieved remarkable
success in the frequency domain. However, its efficacy
in time-domain modeling remains challenging. In the
application of time-domain simulation, we propose to
employ a network to predict the initial solutions for
various source locations within a narrower temporal
scope, which serve as the ICs for physics-guided training
across the entire domain. Leveraging the output from
the initial part as ICs, VE-PINN can accurately simulate
seismic wave propagation.
The remainder of this article is structured as follows.
Section II provides a comprehensive overview of VE-PINN,
detailing its design and implementation. In Section III,
we illustrate the efficacy and accuracy of VE-PINN in seismic
modeling for variable velocity models, encompassing both
two-layered and three-layered configurations. Examples are
presented to showcase the framework’s performance. Following this, VE-PINN is applied to simulate time-domain
wave propagation for diverse source locations, demonstrating
its versatility. This article concludes with a brief summary
in Section IV.
II. M ETHODOLOGY
A. Acoustic Wave Equations
The homogeneous wave equation for a 2-D acoustic
medium, under the conditions of constant density, takes the
form
 2

∂ 2u
∂ 2u
2 ∂ u
=
c
+
(1)
∂t 2
∂x2
∂z 2
where c is the velocity model, a function of space (x, z).
u represents the wavefields to be solved, and (x, z, t) are
spatial and temporal coordinates.
B. Physics-Informed Neural Network
PINN incorporates PDEs into the loss function as regularization terms. This inclusion serves to enhance interpretability,
distinguishing it from conventional data-driven deep learning
methodologies. For the acoustic wave equation given in (1),
PINN uses a neural network to represent the solution of the
equation u(t, x, z), so the PDE residual is given by
 2

∂ 2u
∂ 2u
2 ∂ u
+ 2 .
(2)
f := 2 − c
∂t
∂x2
∂z
In order to train the neural network, we define the loss
function as follows:
MSE = MSEic + εMSEpde

(3)

4507611

Fig. 1. Conventional PINN workflow for the 2-D acoustic wave equation
in a homogeneous model with a velocity of 1.0 km/s (IC corresponds to the
initial conditions).

where
N s1
1 X
2
MSEic =
u(t = t1 , xi , z i ) − u s1
Ns1 i=1

+ ··· +

N sm
1 X
2
u(t = tm , xi , zi ) − u sm
Nsm i=1

(4)

Nf

MSEpde =

1 X  (i) (i) (i)  2
f tf , x f , z f
N f i=1

(5)

where {xi , z i } represent the spatial coordinate samples for the
initial wavefields (u si ) at the time steps between t1 and tm .
(i) N f
{x f(i) , z (i)
f , t f }i=1 specify the collocation points sampled across
the entire domain. Ns1 , Nsm , and N f are the numbers of
sampling points. MSEpde denotes the physics loss controlled
by the wave equation, and MSEic denotes the loss associated
with the IC for the initial wavefield constraint. The parameter ε
serves as a weight factor added to the loss function to balance
the contributions of the two terms. We employ wavefields at m
time steps as ICs. ABCs are not set here, under the assumption
that seismic waves propagate in an infinite space.
The loss function is minimized to update the network
parameters to approximate the solution of the partial differential equation (PDE). It incorporates both an initial loss and
a physics loss, guaranteeing the uniqueness of the solution and
constraining the output within the bounds of a specified physical law. In contrast to conventional data-driven approaches,
the inclusion of the physics loss in PINN serves the dual
purpose of mitigating the need for numerical wavefield solutions and ensuring reasonable accuracy beyond the confines of
the training dataset. Automatic differentiation facilitates more
straightforward gradient calculations, allowing for efficient
updates to the network parameters. To explain this workflow,
we present the application of the proposed approach to the
2-D acoustic wave equation, as depicted in Fig. 1.
C. Velocity-Encoded PINN
By incorporating PDEs into the loss function, along with the
inclusion of initial and boundary conditions, PINN reframes
the problem of solving PDEs as an optimization task.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

4507611

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 62, 2024

Fig. 2. VE-PINN workflow for the 2-D acoustic wave equation for variable two-layered models, where d represents the layer interface depth and (vup , vlow )
specify the velocity in the top and bottom layers, respectively. There are two networks: Neural Network 1 to predict limited steps of the wavefield evolution
(top) and Network 2 trained using physics-guided seismic modeling (bottom). Numerical wavefields Ufdm for some given velocity models are datasets to train
NN 1. Its outputs are predicted solutions Uθ1 for a certain model. Furthermore, Uθ1 is used to provide the ICs to train NN 2. The outputs are wavefields on
arbitrary coordinates in the entire domain of a fixed model.

Nonetheless, challenges persist in addressing the time-domain
wave equation, attributed to the intricate nature of seismic
wavefields and the singularity arising from point sources.
Notably, a limitation of the conventional PINN is its exclusive
applicability to solve the wave equation for a specific velocity
model, posing an evident constraint in practical scenarios.
To overcome this limitation, we propose leveraging neural
networks to establish mappings that connect diverse velocity models and source locations to the corresponding wave
propagation.
To perform seismic wave modeling for multiple velocity
models, we propose to take the velocity model v p as an
input of the network. By incorporating diverse velocity models
along with their corresponding wavefields as ICs, the goal
is for the neural network to adeptly learn the wavefields
associated with new velocity models. Nevertheless, we observe
that the network struggles to effectively capture abrupt variations, particularly those associated with discontinuities at
surfaces. Furthermore, the training of the network proves
challenging due to the discrete nature of velocity, as illustrated
in Section III-B. Building upon the preceding discussion,
we introduce parameters, such as interface depth and velocity,
for each layer to represent distinct velocity models. These
parameters, denoted as feature parameters in this article,
exhibit continuous variation within specific ranges, devoid
of noticeable interruptions. The challenges stemming from

interface discontinuities are mitigated by directly incorporating
interface locations as inputs for the network.
On the other hand, the computing complexity and cost
increase significantly with the feature parameters as inputs to
PINN. In such instances, the neural network is required to
comprehend the wavefields across diverse feature parameters.
Thus, it is essential to forecast the wave propagation for a specific model. Consequently, we introduce a novel decomposed
training approach aimed at diminishing the input dimension
of the PINN and enforcing its training stability. The workflow
is illustrated in Fig. 2, and the specific details are explained
below.
1) VE Wavefield Predictor: As previously discussed, PINN
exclusively solves the wave equation for a specific
velocity model. It means that repeated numerical simulations are required for different velocity models and
source locations. Inspired by supervised learning, we use
the VE method with limited training data. Initially,
numerical wavefields Ufdm are computed for distinct
velocity models using the FDM. We use feature parameters (d, vup , vlow ) to symbolize random two-layered
models, where d represents the layer interface depth
and (vup , vlow ) specify the velocity in the top and bottom layers, respectively. A subset of these wavefields
is then randomly sampled across the entire domain
(x, z, t, d, vup , vlow , Ufdm ) to form a training dataset D.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

ZOU et al.: SEISMIC WAVEFIELDS MODELING WITH VARIABLE HORIZONTALLY LAYERED

4507611

With this dataset D as constraints, Neural Network 1
undergoes training to predict wavefields corresponding
as a function of the two-layered velocity models. Subsequently, the wavefields at three distinct time steps are
chosen as ICs for the second stage of the VE-PINN.
Once trained, Neural Network 1 can extrapolate wavefields for variable velocity models without requiring
retraining of the network. The loss function is defined
as follows:
N

MSENN1 =

v

1 X
2
u xi , z i , ti , di , vupi , vlowi − D
Nv i=1

Fig. 3. Neural Network xs workflow for the 2-D acoustic wave equation for
variable source locations. xs denotes the horizontal source location.

(6)
where (xi , z i , ti , di , vupi , vlowi ) specify the collocation
points sampled across the entire domain, Nv is the
number of sampling points, and D is the limited training
data from FDM.
2) Physics-Guided Seismic Modeling: Our investigation
shows that the pivotal aspect in training PINN lies
in fortifying the constraints related to the ICs, as this
directly influences prediction accuracy. In this stage,
we introduce wavefields at three temporal intervals,
generated using NN1, as the ICs for conducting further seismic simulations for a specific velocity model.
By incorporating constraints related to the ICs and
PDEs, PINN can compute solutions with reasonable
accuracy. Notably, for various velocity models, there is
no need to recalculate the corresponding initial wavefields through traditional numerical methods. In an effort
to mitigate the computational complexity associated with
high-dimensional problems, we opted not to consider
feature parameters as inputs. Consequently, the loss
function is defined as follows:
MSENN2 = MSEic + εMSEpde

(7)

where
Np

MSEpde =

2
1 X
f t pi , x ip , z ip
N p i=1

(8)

MSEic = MSEic1 + MSEic2 + MSEic3
=

Ns1
1 X
|u(xi , z i , ti = ts1 ) − u s1 |2
Ns1 i=1

+

Ns2
1 X
|u(xi , z i , ti = ts2 ) − u s2 |2
Ns2 i=1

+

Ns3
1 X
|u(xi , z i , ti = ts3 ) − u s3 |2
Ns3 i=1

(9)

where MSEic1 , MSEic2 , and MSEic3 denote the residuals
between the given numerical wavefields and the network
prediction results for three time steps. Ns1 , Ns2 , Ns3 , and
N p are the numbers of sampling points for the ICs and
PDE loss.
Fig. 2 shows the workflow of VE-PINN for variable
two-layered velocity models. It can be extended to seismic
modeling for different source locations, which only requires

the replacement of Neural Network 1 with Neural Network xs
in Fig. 3.
D. Network Training
To reduce the computational cost, we use two separate
neural networks to tackle different tasks, which are trained
independently. Neural Network 1 focuses on predicting wavefields for various velocity models without requiring retraining.
For a specific velocity model to be solved, Neural Network 2
performs wavefields simulation across the entire domain.
In Neural Network 1 or Network xs , the inputs comprise
a series of sampling points (x, z, t) and feature parameters
(d, vup , vlow ) or (xs ), yielding the output wavefield Uθ1 corresponding to specific velocity models or source locations. In the
feature parameters, d represents the layer interface depth, and
(vup , vlow ) specify the velocity in the top and bottom layers,
respectively. xs denotes the horizontal source location. During
the training of Network 1, a subset of the numerical wavefields
Ufdm from FDM is employed as the dataset to constrain
the training process, utilizing a learning rate of 5 × 10−4 .
In Neural Network 2, the inputs consist of sampling points
(x, z, t), producing an output wavefield for a specific velocity
model or source location. The training of Network 2 involves
utilizing Uθ1 at specific time steps as ICs, with the learning rate
exponentially decaying from an initial value of 1 × 10−3 every
5000 epochs. ε is set to 1 × 10−4 for all cases. The network
architecture employs a fully connected neural network with a
hyperbolic tangent activation function [35]. There are 80 000
training points randomly sampled in the entire domain. The
training employs an Adam optimizer [36]. All the numerical
examples are performed on an RTX 3090 GPU. The number
of neurons per hidden layer is {64, 64, 64, 64, 64, 32, 32, 32}
for all cases. Algorithm 1 details the training process. The
training pipeline for variable source locations mirrors this
procedure, requiring only the replacement of velocity models
(d, vup , vlow ) with source locations (xs ).
III. R ESULTS
In this section, we test the performance of VE-PINN
for variable layered velocity models, including two-layered
and three-layered models. Utilizing the feature parameters
as inputs, VE-PINN demonstrates enhanced generalization
capabilities across diverse velocity models. In the last case,
we conduct seismic modeling for varying source locations.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

4507611

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 62, 2024

Algorithm 1 VE-PINN for Seismic Modeling for Variable
Two-Layered Velocity Models
Notes: d represents the layer interface depth and (vup , vlow )
specify the velocity in the top and bottom layers, respectively.
Part I: VE wavefield predictor
Goal: Establish a mapping from the velocity models to their
corresponding wavefields.
Initiate: Neural Network 1 parameters θ1 .
For each epoch in Neural Network 1 do
Input: coordinates (x, z, t) and feature parameters
(d, vup , vlow ).
Output: Uθ1 (x, z, t, d, vup , vlow ).
Calculate the loss function of equation (6).
Update: parameters of Neural Network 1 θ1 .
Stop training of Neural Network 1.
Part II: physics-guided seismic modeling
Goal: Simulate the wave propagation as time progresses for
a specific velocity model.
Initiate: Neural Network 2 parameters θ2 .
For each epoch in Neural Network 2 do
Input: coordinates (x, z, t).
Output: Uθ2 (x, z, t).
Calculate the loss function of equation (7). Initial wavefields used in M S E ic are obtained from Uθ1 .
Update: parameters of Neural Network 2 θ2 .

Fig. 4. Three velocity models and their corresponding numerical solutions
(model (a): two-layered model with a velocity of 0.8 and 1.0 km/s in the
top and bottom layers, respectively, and the interface depth is 0.5 km; model
(b): two-layered model with a velocity of 1.0 and 1.4 km/s in the top and
bottom layers, respectively, and the interface depth is 0.3 km; and model
(c): two-layered model with a velocity of 1.0 and 1.2 km/s in the top and
bottom layers, respectively, and the interface depth is 0.6 km).

Through conditioning the network on the source locations,
we observe its capacity to generalize over the given ICs,
obviating the necessity for retraining the network for each
solution.
A. VE Wavefield Predictor
As mentioned earlier, we are focused on the 2-D acoustic
wave equation. First, we use FDM to solve numerical wavefields Ufdm for various two-layer velocity models (d, vup , vlow )
or source locations (xs ). We choose a Ricker wavelet as
the source function to simulate seismic waves. The model
size is 101 × 101 with a spatial spacing of 0.01 km. For
an example velocity model, we plot snapshots (from Ufdm )
at four timesteps in Fig. 4. The coordinates and feature
parameters (x, z, t, d, vup , vlow ) are inputs to Neural Network 1
(Fig. 2), in which we use random points in the domain
(x, z, t, d, vup , vlow , Ufdm ) for training with Ufdm as target. The
predicted solutions subsequently serve as the ICs for Neural
Network 2.
B. Solving the Wave Equation for Various Layered Models
1) Seismic Modeling for Various Two-Layered Models:
First, we demonstrate the performance for two-layered velocity
models with a source depth of 0.2 km. The feature parameters consist of the interface depth d ∈ [0.2, 1 km] and the
velocities in the top and bottom layers, denoted as vup , vlow ∈
[0.6, 2 km/s]. We randomly select 12 samples within the
range (d, vup , vlow ), representing 12 velocity models. In the

Fig. 5. Comparison between the wavefields predicted by VE-PINN and FDM.
The first row displays VE-PINN solutions, the second one exhibits numerical
wavefields from FDM, and the difference is shown in the third row (model
(a): two-layered model with a velocity of 1.4 and 0.8 km/s in the top and
bottom layers, respectively, and the interface depth is 0.4 km and model (b):
two-layered model with a velocity of 1.0 and 1.2 km/s in the top and bottom
layers, respectively, and the interface depth is 0.5 km).

domain x, z ∈ [0, 1 km], t ∈ [0, 1 s], we use FDM to
calculate numerical wavefields Ufdm for the 12 velocity
models and randomly sample 15 000 points in the domain
(x, z, t, d, vup , vlow , Ufdm ) as training data. After 30 000 epochs
of Neural Network 1, the outputs are wavefields Uθ1 at
t = 0.1, 0.2, and 0.4 s for the velocity models in Fig. 5
(which are not included in the training set). The training
of Network 1 is then halted. In the stage “physics-guided
seismic modeling,” we take Uθ1 as the ICs to train Neural
Network 2 for 60 000 epochs. PINN can predict wavefields
within t = 0 − 1 s, and the results are shown in Fig. 5.
The first row displays VE-PINN solutions, while the second
row exhibits numerical wavefields from FDM. Both rows
depict the wave propagation over time, demonstrating accurate
agreement between VE-PINN solutions and the reference ones.
By conditioning Network 1 on velocity models, VE-PINN can
effectively simulate wavefields on models not included in the
original dataset.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

ZOU et al.: SEISMIC WAVEFIELDS MODELING WITH VARIABLE HORIZONTALLY LAYERED

4507611

TABLE I
C OMPARISON B ETWEEN C OMPUTATIONAL C OSTS FOR C ASES 1–3

Fig. 6. Comparison between the wavefields predicted in Cases 1–3 (using the
conventional PINN, we add the feature parameters as inputs (Case 1) and the
entire velocity models v p as inputs (Case 2); in Case 3, we use the proposed
VE-PINN).

To illustrate the effectiveness of VE-PINN, we compare its performance with the conventional PINN. Take
model (b) in Fig. 5 as an example, with a velocity of 1.0 and
1.2 km/s in the top and bottom layers, respectively, and an
interface depth of 0.5 km. Using PINN, we add the feature
parameters as inputs (Case 1) and the entire velocity models
v p as inputs (Case 2). The ICs for network training in
Cases 1 and 2 are the same as ones in VE-PINN, including
12 velocity models and their corresponding wavefields. Fig. 6
illustrates a comparison among Case 1, Case 2, and VE-PINN
(Case 3). The computational time and error records are presented in Table I. It is evident from the results that VE-PINN,
as discussed in this study, exhibits a notable advantage by
requiring less time for achieving higher accuracy. Moreover,
it demonstrates an enhanced capability in capturing the variations of wavefields at the interface.
We present the training loss curve for the current case,
depicted in Fig. 7. For Case 2, the loss curve converges slowly.
For Case 3, Neural Network 2 conducts seismic wavefield simulation for a specific velocity model, utilizing predictions from
Network 1 as the IC. It shows a better and faster convergence
compared with Case 1, due to the decreased computational
complexity. Although the loss curve for Case 1 diminishes
to a lower value, the high-dimensional modeling in PINNs
increases the computational complexity, leading to diminished
efficiency and accuracy, as demonstrated in Table I.
2) Seismic Modeling for Various Three-Layered Models:
The proposed method is readily applicable to models featuring
three or more layers, which only needs to modify the feature
parameters. In consideration of geological circumstances, it is
generally observed that, under most conditions, the velocity
within the deeper layer surpasses that in shallower one.

Fig. 7. Training loss for the two-layered velocity model as a function of
epochs for Cases 1–3 (using the conventional PINN, we add the feature
parameters as inputs (Case 1) and the entire velocity models v p as inputs
(Case 2); in Case 3, we use the proposed VE-PINN and plot the training loss
of the network for physics-guided seismic modeling).

Fig. 8.

Three-layered model used in this article.

Assuming that the velocity in the sedimentary rock is within
the range 1.5–6.0 km/s, we set a three-layered horizontal
model. The thickness and velocity specifics for each layer are
illustrated in Fig. 8.
We set a velocity model shown in Fig. 8, and the
domain interest spans the range x, z ∈ [0, 2 km] and
t ∈ [0, 1.2 s]. The feature parameters include the interface
depth (d1 , d2 ) ∈ [0, 2 km], in which d1 < d2 , and the
velocity vup , vlow , vmid ∈ [0.3, 3 km/s] in the top, middle, and
bottom layers, respectively. We randomly select 14 sampling
points in the domain (d1 , d2 , vup , vlow , vmid ), corresponding
to 14 velocity models. We use FDM to calculate numerical
wavefields Ufdm and randomly sample 30 000 points in the
domain (x, z, t, d1 , d2 , vup , vlow , vmid , Ufdm ) as training data.
After 30 000 epochs of Neural Network 1, wavefields Uθ1 are
generated at t = 0.1, 0.2, and 0.5 s for the velocity model
in Fig. 8 (not used in the training set), and subsequently, the
training of Network 1 is halted. In the stage “physics-guided
seismic modeling,” we take Uθ1 as the ICs to train Neural Network 2 for 60 000 epochs. PINN can predict wavefields within
t = 0 − 1.2 s, and the results are shown in Fig. 9. Wavefields
predicted by VE-PINN and numerical modeling are shown in
the first and second rows, respectively. We observe that the

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

4507611

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 62, 2024

TABLE II
C OMPARISON OF P REDICTION T IME C OST B ETWEEN VE-PINN AND FDM

Fig. 10. Three-layered model used in this section for multisource seismic
modeling.

Fig. 9. Comparison between wavefields predicted by VE-PINN and numerical
solutions.

error between the predicted solutions and reference ones is
relatively small. Encoding the interface depth directly into the
neural network input enables faster capture of the velocity
variation within each layer. VE-PINN has the capability to
simulate wave phenomena, including reflected and transmitted
waves generated at various interfaces.
VE-PINN can generalize over given velocity models in the
dataset and simulate their corresponding wavefields. In contrast to prevailing methods that necessitate the recalculation
of numerical solutions using FDM for each unique IC,
VE-PINN obviates the need for repetitive computations
once the network has undergone training. A comparison
of the computational cost associated with predicting initial wavefields through VE-PINN and FDM is presented
in Table II.
C. Seismic Modeling for Various Source Locations
The proposed methods described above readily apply themselves to the extension of time-domain seismic simulation for
various source locations. Multisource seismic modeling in the
frequency domain has found extensive application. However,
challenges persist in the time domain, primarily concerning
computational cost and complex wave dynamics. In this
section, we position the point source at a depth of 0.2 km.
We use a three-layered model with a velocity of 0.8, 1.0, and
1.2 km/s in the top, middle, and bottom layers, respectively,
with interfaces in the depth of 0.4 and 0.7 km (see Fig. 10).
The domain interest spans the range x, z ∈ [0, 1 km], t ∈
[0, 1.1 s]. The horizontal coordinates of the source location,
denoted as xs and falling within the range [0, 1 km], serve
as inputs to the network. The network, denoted as Neural

Fig. 11. Comparison between solutions predicted by VE-PINN and numerical
wavefields (xs = 0.2 km).

Network xs , is trained using numerical wavefields obtained
at source locations xs = 0.3, 0.4, 0.6, and 0.7 km. The resultant dataset is utilized to train Neural Network xs , which,
in turn, produces wavefields Uθs corresponding to three new
source locations xs = 0.2, 0.5, and 0.8 km at three distinct
timesteps t = 0.1, 0.3, and 0.6 s after 30 000 training epochs.
Employing Uθs as ICs, and guided by the wave equation
as physical constraints, Neural Network 2 predicts solutions,
as illustrated in Figs. 11–13, after 60 000 training epochs. The
wave phenomena can be captured by the network, including
reflected waves generated by the interfaces. During the training
of Network xs , the temporal domain of interest spans the
range t ∈ [0, 0.6 s]. In Network 2, it is trained within the
range t ∈ [0, 1.1 s]. Different from multisource simulation
in the frequency domain, we use two networks to perform

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

ZOU et al.: SEISMIC WAVEFIELDS MODELING WITH VARIABLE HORIZONTALLY LAYERED

4507611

TABLE III
C OMPARISON OF N ETWORK T RAINING T IME C OST B ETWEEN VE-PINN AND PINN

Fig. 12. Comparison between solutions predicted by VE-PINN and numerical
wavefields (xs = 0.5 km).

Fig. 13. Comparison between solutions predicted by VE-PINN and numerical
wavefields (xs = 0.8 km).

time-domain modeling. The first network serves as a supervised training for various sources, while Network 2 employs
physics-informed fine-tuning across the entire domain. In this
scenario, VE-PINN effectively simulates wave propagation
and demonstrates generalization across varying source locations. A comparison of the computational cost associated with
network training through VE-PINN and the conventional one
is presented in Table III.
IV. D ISCUSSION AND C ONCLUSION
We developed a seismic modeling approach referred to
as VE PINN. This method involves the encoding of feature
parameters, representing velocity models and source locations,

into the network inputs. Recognizing the neural network’s
inclination to adeptly capture nonlinear connections between
continuous parameters and their associated solutions, our
study introduces continuous feature parameters to represent the discontinuous velocity models. This approach not
only aligns with the neural network’s capability, but also
addresses the inherent discontinuity of the velocity model.
Consequently, for the simulation of diverse velocity models or source locations, the necessity to recompute initial
wavefields using conventional numerical methods is obviated, resulting in a notable reduction in computational
expenses.
Inspired by principles of supervised learning, the proposed
method uses limited data from FDM to train a first neural
network to forecast solutions across diverse velocity models. The findings demonstrate the network’s capability to
generalize over the provided ICs within the dataset. These
solutions, in turn, furnish a more dependable foundation
for initializing PINN in the subsequent stage. Adhering
to the constraints imposed by both the ICs and PDEs,
PINN exhibits a commendable ability to predict solutions
with reasonable accuracy. The numerical outcomes indicate
that the VE-PINN successfully predicts wave propagation
for timesteps beyond its training data and accommodates
changes in velocity models or source locations. This adaptability renders VE-PINN applicable in seismic migration and
inversion.
From the accuracy aspect, VE-PINN is immune to numerical dispersion, which is a problem for numerical wave equation
solvers, such as FDM. From the efficiency aspect, VE-PINN
has the potential to implement seismic wave simulation for
various models and sources more efficiently than FDM. As a
mesh-free method, it also mitigates the challenge we often face
when the domain has a complex shape, such as topography.
For the performance of VE-PINN on the velocities out of
the given range, it is an important aspect we will test in
the further research. The method can also be applicable to
problems defined in a larger domain or models featuring
three or more layers, which only requires a modification to
the input coordinates and feature parameters. For nonhorizontally layered models, we can also use feature parameters
to represent various reflectors, such as faults or anomalies.
The limitation lies in the challenge of generalizing across
velocity models with varying numbers of layers. In addition,
new methods need to be proposed to perform seismic wave
simulation for complex nonlayered models, such as Marmousi
models. Alternatively, we can use more advanced deep learning techniques. Song et al. [37] used physics-informed Fourier
neural operator to simulate multisource seismic travel times in
variable velocity models. Moseley et al. [38] used a WaveNet

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

4507611

IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 62, 2024

architecture to simulate seismic waves in horizontally layered
media and proposed a conditional autoencoder network to deal
with faulted media with arbitrary layers and fault properties.
Zhou et al. [39] used U-Net to predict various complex
subsurface velocity fields, including anticlines, synclines, and
anomalous velocity models. These methods will be further
investigated in the future work.
R EFERENCES
[1] Z. Alterman and F. Karal Jr., “Propagation of elastic waves in layered
media by finite difference methods,” Bull. Seismol. Soc. Amer., vol. 58,
no. 1, pp. 367–398, 1968.
[2] J. Lysmer and L. A. Drake, “A finite element method for seismology,” Methods Comput. Phys., Adv. Res., vol. 11, pp. 181–216,
Jan. 1972.
[3] D. Komatitsch and J.-P. Vilotte, “The spectral element method:
An efficient tool to simulate the seismic response of 2D and 3D
geological structures,” Bull. Seismo. Soc. Amer., vol. 88, pp. 368–392,
Apr. 1998.
[4] S. Cuomo, V. S. Di Cola, F. Giampaolo, G. Rozza, M. Raissi, and
F. Piccialli, “Scientific machine learning through physics–informed
neural networks: Where we are and what’s next,” J. Sci. Comput., vol. 92,
no. 3, p. 88, Sep. 2022.
[5] M. Raissi, P. Perdikaris, and G. E. Karniadakis, “Physics-informed
neural networks: A deep learning framework for solving forward and
inverse problems involving nonlinear partial differential equations,”
J. Comput. Phys., vol. 378, pp. 686–707, Feb. 2019.
[6] W. Ji, W. Qiu, Z. Shi, S. Pan, and S. Deng, “Stiff-PINN: Physicsinformed neural network for stiff chemical kinetics,” J. Phys. Chem. A,
vol. 125, no. 36, pp. 8098–8106, Sep. 2021.
[7] S. Cai, Z. Mao, Z. Wang, M. Yin, and G. E. Karniadakis,
“Physics-informed neural networks (PINNs) for fluid mechanics:
A review,” Acta Mechanica Sinica, vol. 37, no. 12, pp. 1727–1738,
Dec. 2021.
[8] W. Wu, M. Daneker, M. A. Jolley, K. T. Turner, and L. Lu, “Effective data sampling strategies and boundary condition constraints of
physics-informed neural networks for identifying material properties in
solid mechanics,” Appl. Math. Mech., vol. 44, no. 7, pp. 1039–1068,
Jul. 2023.
[9] P. Ren, C. Rao, S. Chen, J.-X. Wang, H. Sun, and Y. Liu, “SeismicNet: Physics-informed neural networks for seismic wave modeling in
semi-infinite domain,” Comput. Phys. Commun., vol. 295, Feb. 2024,
Art. no. 109010.
[10] T. Alkhalifah, C. Song, U. B. Waheed, and Q. Hao, “Wavefield solutions
from machine learned functions constrained by the Helmholtz equation,”
Artif. Intell. Geosci., vol. 2, pp. 11–19, Dec. 2021.
[11] G. Pang, L. Lu, and G. E. Karniadakis, “FPINNs: Fractional physicsinformed neural networks,” SIAM J. Sci. Comput., vol. 41, no. 4,
pp. A2603–A2626, Jan. 2019.
[12] X. Meng, Z. Li, D. Zhang, and G. E. Karniadakis, “PPINN:
Parareal physics-informed neural network for time-dependent
PDEs,” Comput. Methods Appl. Mech. Eng., vol. 370, Oct. 2020,
Art. no. 113250.
[13] E. Kharazmi, Z. Zhang, and G. E. Karniadakis, “Variational physicsinformed neural networks for solving partial differential equations,”
2019, arXiv:1912.00873.
[14] L. Lu, R. Pestourie, W. Yao, Z. Wang, F. Verdugo, and S. G. Johnson,
“Physics-informed neural networks with hard constraints for inverse
design,” SIAM J. Sci. Comput., vol. 43, no. 6, pp. B1105–B1132,
Jan. 2021.
[15] U. B. Waheed, E. Haghighat, T. Alkhalifah, C. Song, and Q. Hao,
“Eikonal solution using physics-informed neural networks,” in
Proc. EAGE Annu. Conf. Exhib. Online, 2020, vol. 2020, no. 1,
pp. 1–5.
[16] U. B. Waheed, E. Haghighat, T. Alkhalifah, C. Song, and Q. Hao,
“PINNeik: Eikonal solution using physics-informed neural networks,”
Comput. Geosci., vol. 155, Oct. 2021, Art. no. 104833.
[17] C. Song and T. A. Alkhalifah, “Wavefield reconstruction inversion via
physics-informed neural networks,” IEEE Trans. Geosci. Remote Sens.,
vol. 60, 2022, Art. no. 5908012.

[18] C. Song, T. Alkhalifah, and U. B. Waheed, “Solving the frequencydomain acoustic VTI wave equation using physics-informed neural networks,” Geophys. J. Int., vol. 225, no. 1, pp. 846–859,
Dec. 2020.
[19] C. Song, T. Alkhalifah, and U. B. Waheed, “A versatile framework to solve the Helmholtz equation using physics-informed neural networks,” Geophys. J. Int., vol. 228, no. 3, pp. 1750–1762,
Sep. 2021.
[20] X. Huang and T. Alkhalifah, “PINNup: Robust neural network wavefield
solutions using frequency upscaling and neuron splitting,” J. Geophys.
Res., Solid Earth, vol. 127, no. 6, Jun. 2022, Art. no. e2021JB023703.
[21] X. Huang and T. Alkhalifah, “Single reference frequency loss for
multifrequency wavefield representation using physics-informed neural networks,” IEEE Geosci. Remote Sens. Lett., vol. 19, pp. 1–5,
2022.
[22] C. Song and Y. Wang, “Simulating seismic multifrequency wavefields
with the Fourier feature physics-informed neural network,” Geophys.
J. Int., vol. 232, no. 3, pp. 1503–1514, Nov. 2022.
[23] Y. Wu, H. S. Aghamiry, S. Operto, and J. Ma, “Helmholtz-equation
solution in nonsmooth media by a physics-informed neural network
incorporating quadratic terms and a perfectly matching layer condition,”
Geophysics, vol. 88, no. 4, pp. T185–T202, Jul. 2023.
[24] T. Alkhalifah and X. Huang, “Physics-informed neural wavefields with
Gabor basis functions,” 2023, arXiv:2310.10602.
[25] B. Moseley, A. Markham, and T. Nissen-Meyer, “Solving the wave
equation with physics-informed deep learning,” 2020, arXiv:2006.11894.
[26] B. Moseley, A. Markham, and T. Nissen-Meyer, “Finite basis physicsinformed neural networks (FBPINNs): A scalable domain decomposition
approach for solving differential equations,” Adv. Comput. Math.,
vol. 49, no. 4, p. 62, Aug. 2023.
[27] M. Rasht-Behesht, C. Huber, K. Shukla, and G. E. Karniadakis,
“Physics-informed neural networks (PINNs) for wave propagation and
full waveform inversions,” J. Geophys. Res., Solid Earth, vol. 127, no. 5,
May 2022, Art. no. e2021JB023120.
[28] S. Alkhadhr and M. Almekkawy, “Wave equation modeling via physicsinformed neural networks: Models of soft and hard constraints for
initial and boundary conditions,” Sensors, vol. 23, no. 5, p. 2792,
Mar. 2023.
[29] Y. Zhang, X. Zhu, and J. Gao, “Seismic inversion based on acoustic
wave equations using physics-informed neural network,” IEEE Trans.
Geosci. Remote Sens., vol. 61, 2023, Art. no. 4500511.
[30] L. Wang, H. Wang, L. Liang, J. Li, Z. Zeng, and Y. Liu, “Physicsinformed neural networks for transcranial ultrasound wave propagation,”
Ultrasonics, vol. 132, Jul. 2023, Art. no. 107026.
[31] J. Cheng Wong, C. Ooi, A. Gupta, and Y.-S. Ong, “Learning in
sinusoidal spaces with physics-informed neural networks,” IEEE Trans.
Artif. Intell., vol. 5, no. 3, pp. 985–1000, Jul. 2022.
[32] H. Nosrati and M. Emami Niri, “Manipulating the loss calculation
to enhance the training process of physics-informed neural networks
to solve the 1D wave equation,” Eng. Comput., vol. 2023, pp. 1–29,
Sep. 2023.
[33] J. Zou, C. Liu, C. Song, and P. Zhao, “Numerical solver-independent
seismic wave simulation using task-decomposed physics-informed neural networks,” IEEE Geosci. Remote Sens. Lett., vol. 20, pp. 1–5, 2023.
[34] M. H. Taufik and T. Alkhalifah, “LatentPINNs: Generative physicsinformed neural networks via a latent representation learning,” 2023,
arXiv:2305.07671.
[35] S. Sharma, S. Sharma, and A. Athaiya, “Activation functions in neural
networks,” Towards Data Sci., vol. 4, no. 12, pp. 310–316, 2017.
[36] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
2014, arXiv:1412.6980.
[37] C. Song, T. Zhao, U. B. Waheed, C. Liu, and T. You, “Seismic traveltime
simulation for variable velocity models using physics-informed Fourier
neural operator,” 2023, arXiv:2311.03751.
[38] B. Moseley, T. Nissen-Meyer, and A. Markham, “Deep learning for fast
simulation of seismic waves in complex media,” Solid Earth, vol. 11,
no. 4, pp. 1527–1549, Aug. 2020.
[39] Y. Zhou, L. Han, P. Zhang, J. Zeng, X. Shang, and W. Huang, “Microseismic data-direct velocity modeling method based on a modified
attention U-Net architecture,” Appl. Sci., vol. 13, no. 20, p. 11166,
Oct. 2023.
[40] S. M. Mousavi, G. C. Beroza, T. Mukerji, and M. Rasht-Behesht,
“Applications of deep neural networks in exploration seismology:
A technical survey,” Geophysics, vol. 89, no. 1, pp. WA95–WA115,
Jan. 2024.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

ZOU et al.: SEISMIC WAVEFIELDS MODELING WITH VARIABLE HORIZONTALLY LAYERED

4507611

Jingbo Zou received the B.S. degree from the College of Geo-Exploration Science and Technology,
Jilin University, Changchun, China, in 2021, where
she is currently pursuing the Ph.D. degree.
She is currently a Visiting Student with the
Resource Geophysics Academy, Imperial College
London, London, U.K. Her research interests include
seismic modeling, full waveform inversion, and
machine learning applications in geophysics.

Pengfei Zhao received the B.S. degree in information and computing sciences, the M.S. degree in
operations research and cybernetics, and the Ph.D.
degree in engineering mathematics from Jilin University, Changchun, China, in 2005, 2007, and 2010,
respectively.
From 2012 to 2013, he was a Visiting Scholar
at the Department of Scientific Computing, Florida
State University, Tallahassee, FL, USA. He is currently an Associate Professor with Jilin University.
His research interests include geostatistical inversion
and machine learning applications in geophysics.

Cai Liu received the B.S. degree in applied
geophysics and the M.S. and Ph.D. degrees in
geo-exploration and information technology from
Jilin University, Changchun, China, in 1986, 1993,
and 1999, respectively.
From 1996 to 2000, he was an Associate Professor
at Jilin University, where he became a Professor,
in 2000, and a Distinguished Professor of Jilin
Province, China, in 2008. He was the Director of
the College of Geo-Exploration Science and Technology, Jilin University, from 2004 to 2017. He has
been with the Ten Thousand Talent Program since 2018. His research interests
include integrated research of geophysics and geology.

Chao Song received the B.S. degree in geophysics
from the College of Geo-Exploration Science and
Technology, Jilin University, Changchun, China,
in 2013, and the Ph.D. degree from the Seismic Wave Analysis Group (SWAG), King Abdullah
University of Science and Technology (KAUST),
Thuwal, Saudi Arabia, in 2020.
He worked as a Research Associate at the Centre
for Reservoir Geophysics, Imperial College London,
London, U.K., from 2021 to 2022. He is currently a
Professor of geophysics with Jilin University. His
research interests include full waveform inversion and machine learning
applications in geophysics.

Authorized licensed use limited to: Universidad EAFIT. Downloaded on July 31,2024 at 19:49:51 UTC from IEEE Xplore. Restrictions apply.

