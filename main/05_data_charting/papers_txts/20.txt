Downloaded 08/27/24 to 200.12.181.232. Redistribution subject to SEG license or copyright; see Terms of Use at http://library.seg.org/page/policies/terms
DOI:10.1190/image2022-3745050.1

Elastic-AdjointNet : A physics guided deep autoencoder to overcome cross talk effects in
multiparameter full waveform inversion
Arnab Dhara*, Mrinal Sen, University of Texas at Austin

Summary
Full Waveform Inversion (FWI) is the most popular
technique to obtain high resolution estimates of earth model
parameters using all information present in seismic. Elastic
FWI inverts multicomponent data for P and S-wave
velocities and densities. We propose an alternative approach
for FWI using a combination of machine learning and the
physics of wave propagation. Unlike a conventional
supervised machine learning, we do not require known
answers to train our network. The multicomponent shot
gathers are input to a convolutional neural network (CNNs)
based auto encoder whose outputs are used as P-wave, Swave and density models that are used to compute synthetic
seismograms using the stress-velocity formulation of the
elastic wave equation. The synthetic data are compared
against observed input data and the misfit is estimated. The
gradient of the misfit with respect to the velocity model
parameters is calculated using the adjoint state method. The
adjoint state gradient is then used to update the network
weights using the automatic differentiation technique. Once
the misfit term converges, the neural network can generate
subsurface models consistent with the observed data. We
observe that the neural network can capture spatial
correlations at different scales and thus can introduce
regularization in our inverse problem. The regularization is
enough to mitigate the cross-talk problem in elastic FWI and
also produce good results in areas with low illumination.

convergence. They are created because different elastic
parameters may have same radiation pattern (Pan et al.,
2019; Keating and Innanen, 2020; Kamath and Tsvankin,
2016).
Recent works have used deep learning-based models to learn
the mapping from seismic gathers to velocity models (Kazei
et al., 2021; Yang and Ma, 2019). A deep learning approach
is a purely supervised technique, the goal of which is to learn
from a large amount of paired seismic data and
corresponding true velocity maps. This approach is agnostic
to the physics of wave propagation. Because of the limited
availability of labelled datasets, this approach has been
limited to simpler velocity models. Moreover, the large
memory requirements of deep learning libraries have limited
the application of such approaches to only acoustic imaging.
In this work we introduce a physics constrained machine
learning framework Elastic-AdjointNet, which allows users
to embed their elastic wave physics codes in deep learning
libraries and develop neural network workflows. Previous
approaches to embed multiparameter full-waveform
inversion (FWIs) in deep learning framework required
reimplementation of PDEs as recurrent neural networks
(RNNs) (Wang et al., 2021; Zhang et al., 2021). This reimplementation of PDEs may not be an attractive option for
geoscientists that are working with wave propagation codes
that have been developed for decades with sophisticated
discretization techniques.

Introduction
Since early development of the theory (Tarantola, 1984),
successful application of FWI has been reported in
exploration seismology, earthquake seismology, deep
crustal imaging, and medical imaging. Using a Partial
Equation Differential Equation (PDE) solver to generate
synthetic seismograms and a local optimization method,
FWI iteratively updates the subsurface model parameters by
reducing the misfit between recorded data/observed data and
the estimated data. However, utilizing FWI only to estimate
P-wave velocity (acoustic imaging) limits its benefits when
applying to problems like reservoir characterization and near
surface geophysics.
Current Elastic FWI algorithms suffers from a critical issue.
Elastic FWI suffers from the issue of interparameter tradeoff or crosstalk (Operto et al., 2013). Cross-talk occurs when
data residuals caused by an error in the estimate of one
physical property are attributed to another, impeding

In this work, we propose a new network the input to which
is the multicomponent shot gathers. The output of the network, which is a velocity model is fed to a physics based
PDE solver. The physics based PDE solver generates
synthetic seismic data. The synthetic seismic data is
compared with the observed data and the gradient of the
misfit between observed and synthetic data is used to update
the network weights. The schematic of the proposed
approach is shown in Figure 1.
The above idea has its origins from the works of Calder√≥nMac√≠as et al. (2000) and Biswas et al. (2019). In this work,
we use the adjoint state method to calculate the gradient of
the misfit and then backpropagate it throughout the network
to update its weights. Ulyanov et al. (2018) applied untrained
Convnets to solution of problems like image restoration,
interpolation and demonstrated capability of neural
networks to capture great deal of priors from images.
NNFWI (Zhu et al., 2021) which was based on a similar

Second International Meeting for Applied Geoscience & Energy
10.1190/image2022-3745050.1
Page 882
¬© 2022 Society of Exploration Geophysicists and the American Association of Petroleum Geologists

Downloaded 08/27/24 to 200.12.181.232. Redistribution subject to SEG license or copyright; see Terms of Use at http://library.seg.org/page/policies/terms
DOI:10.1190/image2022-3745050.1

FWI using physics guided autoencoder

concept showed improved acoustic FWI result in presence
of gaussian data noise. We demonstrate that the reparameterization of the model parameters using neural
networks and optimization using Adam (Kingma
and Ba, 2014) algorithm introduces regularization , thus
overcoming local minima and crosstalk issues in elastic
FWI. Moreover, the regularization helps to produce robust
results in area of low data coverage.
Method
We use the time domain formulation of elastic wave
equation to invert for P-wave velocity (Vp), S-wave velocity
(Vs) and density (œÅ). The objective function is formulated as
1
ùê∏ = 2 ‚àëùë† ‚àëùëü ‚à´[ùëëùëúùëèùë† ‚àí ùëëùë†ùë¶ùëõùë°‚Ñé ]2 ùëëùë°,
where ùëëùëúùëèùë† is observed wavefield and ùëëùë†ùë¶ùëõùë°‚Ñé is the
calculated wavefield at sources s and receivers r. We use the
eighth-order staggered grid finite difference scheme in space
and second order in time of the velocity-stress formulation
of the elastic wave equation (K√∂hn et al., 2012).
We used an encoder-decoder type of neural network. The
multicomponent data is given as input to two convolutional
layers at the starting of the network. The number of input
channels is equal to the number of receivers and the number
of output channel is equal to one. A third convolutional layer
with two input channels takes the two inputs, combines
them, and gives an output which is given to rest of the
network. The rest of the network has an encoder network
then generates low-dimensional feature maps (z) through a
sequence of convolution blocks and maxpooling layers. The
same low dimensional feature map (z) is now fed into 3
separate decoder networks, output from the decoders
represent three different elastic model parameters.
Our decoder transforms the feature maps into
velocity/density models (y) using a sequence of convolution
blocks and upsampling layers. The architecture of our
network is shown in Figure 2. Each convolution block
consists of two convolution layers and two ReLU units. Each
convolution block outputs twice the input channels. The
maxpooling layers reduce the size of the feature maps by a
factor of two. The output of the encoder is connected to a
linear layer which generates latent representation. The final
output of the encoder is a 1D latent vector. This sequence of
convolutional blocks and maxpooling layers thus transforms
the high dimensional inputs into a low dimensional latent
space representation.
The low dimensional latent space is given as input to the decoder. The decoder consists of convolutional blocks interleaved with upsampling layers. The components of the convolutional blocks are the same as those of the encoder. Each
convolution block outputs half the input channels. The
upsampling layers increase the lateral feature dimensions by

a factor of 2. The output of the decoder is fed into a
convolutional layer which reduces the channel dimension to
1. The intermediate output is added to a starting model and
given as input to our PDE. To train our network we use
Adam optimization using a learning rate of 0.005.
Experiments
To test the effectiveness of our approach, we generated an
elastic test model and named it as the STH (Square-TriangleHourglass) model. The model is inspired from the CTS
model, demonstrated in Dokter et al. (2017). The model
consists of an elastic layer over a half-space. Except for a
free surface boundary condition, on all the other sides
absorbing boundary conditions are applied. Present inside
the elastic layer, are bodies of three different geometrical
shapes: 4 squares on the Vp model, 4 triangles on the Vs
model and 4 hourglass on the œÅ model. All the bodies are
placed by taking care to ensure bodies of different shapes
don‚Äôt occupy the same (x,y) position on the 2D grid. This is
not a representation of the true earth, but a good model to
demonstrate the inherent crosstalk in multiparameter
full waveform inversion. The grid size of the velocity model
is 150x294 with a grid interval of 10 m. A Ricker wavelet
with a peak frequency of 10 Hz is used as the source. We
simulate 28 shots with 223 receivers. The sources are placed
at equal distance. Each shot record has 5000 samples with a
sampling interval of 1 ms. The true model along with the
source (in white) and receiver (in pink) position is shown in
Figure 3a.
We choose to invert for velocities and densities since model
parameterization using velocities show weakest cross-talk
effects when compared to elastic inversion using Lam√©
parameterization (K√∂hn et al., 2012). The effect of crosstalk
can further be damped by performing the inversion in a
multiscale way, starting from a band having a low value of
maximum frequency and going up to a band having the
maximum frequency content present in the data. The starting
model for inversion contained correct elastic material
parameters for the layer and the half space but without the
geometrical structures. To compare our proposed approach,
we show the results of a conventional multiscale inversion
in Figure 3. A sequential inversion of the frequency bands
up to 2, 5, 10 and 20 Hz using L-BFGS algorithm was carried
out in case of conventional FWI. Even with a multiscale
strategy the crosstalk artifacts can be clearly seen in the
results in Figure 3b. The crosstalk artifacts are highlighted
by green arrows. Moreover, in areas of low data coverage
(highlighted by red arrow), the inversion shows significant
artifacts. Inversion using our proposed Elastic-AdjointNet
shows significantly no such artifacts even in areas of low
data coverage (Figure 3c). Notice from the convergence
curve (Figure 4), we don‚Äôt use a multiscale approach when
using our neural network for inversion.

Second International Meeting for Applied Geoscience & Energy
10.1190/image2022-3745050.1
Page 883
¬© 2022 Society of Exploration Geophysicists and the American Association of Petroleum Geologists

Downloaded 08/27/24 to 200.12.181.232. Redistribution subject to SEG license or copyright; see Terms of Use at http://library.seg.org/page/policies/terms
DOI:10.1190/image2022-3745050.1

FWI using physics guided autoencoder

Figure 1: Workflow for deep learning based elastic full waveform inversion

Figure 2: Autoencoder architecture

Figure 3: Inversion results: a) True model b) Conventional inversion c) Proposal approach

Second International Meeting for Applied Geoscience & Energy
10.1190/image2022-3745050.1
Page 884
¬© 2022 Society of Exploration Geophysicists and the American Association of Petroleum Geologists

Downloaded 08/27/24 to 200.12.181.232. Redistribution subject to SEG license or copyright; see Terms of Use at http://library.seg.org/page/policies/terms
DOI:10.1190/image2022-3745050.1

FWI using physics guided autoencoder

Figure 4 : Convergence curve
The network architecture is particularly suitable for avoiding
the issue of local minima and cross talk effects in elastic
FWI. We interpret that the encoder carries out a regularized
inverse operation resulting in sparse latent representation of
the velocity model. The decoder then transforms this to a
higher dimension using a nonlinear operation. Since three
separate decoders with different network weights are used to
upscale the same latent space, the crosstalk issue can be
mitigated using the proposed approach.
In our proposed approach, the gradient calculation is implemented in C language using the MPI framework and the network update is done in the Pytorch (Paszke et al., 2019)
framework. A python API connects the two; run time for one
iteration was 60 seconds.
Next, we apply the proposed network for elastic inversion of
the geologically realistic Marmousi-II model. The gridsize
for the velocity model is 100x300 with grid spacing of 0.02
km. A Ricker wavelet of peak frequency 10 Hz is used as the
source. We simulate 35 shots over 276 receivers. The true
model, the initial model and the final inversion results are
shown in Figure 5.
Conclusion
We combined a deep convolutional autoencoder with a
physics based forward modeling code for elastic FWI. The
proposed approach overcomes local minima and cross talk
issues. Here, we used a deterministic autoencoder to solve
our inverse problem. In future, we plan to test a variational
autoencoder which shall aid in quantifying uncertainty in
multiparameter full waveform inversion.
Acknowledgements
This project is partially supported by EDGER forum at
Jackson School of Geosciences, UT-Austin

Figure 5: Marmousi Inversion models a) True b)
Initial c) Inverted

Second International Meeting for Applied Geoscience & Energy
10.1190/image2022-3745050.1
Page 885
¬© 2022 Society of Exploration Geophysicists and the American Association of Petroleum Geologists

Downloaded 08/27/24 to 200.12.181.232. Redistribution subject to SEG license or copyright; see Terms of Use at http://library.seg.org/page/policies/terms
DOI:10.1190/image2022-3745050.1

References
Biswas, R., M. K. Sen, V. Das, and T. Mukerji, 2019, Prestack and poststack inversion using a physics- guided convolutional neural network:
Interpretation, 7, SE161‚ÄìSE174, doi: https://doi.org/10.1190/INT-2018-0236.1.
Calder√≥n-Mac√≠as, C., M. K. Sen, and P. L. Stoffa, 2000, Artificial neural networks for parameter estimation in geophysics: Geophysical Prospecting,
48, 21‚Äì47, doi: https://doi.org/10.1046/j.1365-2478.2000.00171.x.
Dokter, E., D. K√∂hn, D. Wilken, D. De Nil, and W. Rabbel, 2017, Full waveform inversion of sh-and love-wave data in near-surface prospecting:
Geophysical Prospecting, 65, 216‚Äì236, doi: https://doi.org/10.1111/1365-2478.12549.
Kamath, N., and I. Tsvankin, 2016, Elastic full-waveform inversion for VTI media: Methodology and sensitivity analysis: Geophysics, 81, C53‚ÄìC68,
doi: https://doi.org/10.1190/geo2014-0586.1.
Kazei, V., O. Ovcharenko, P. Plotnitskii, D. Peter, X. Zhang, and T. Alkhalifah, 2021, Mapping full seismic waveforms to vertical velocity profiles by
deep learning: Geophysics, 86, R711‚ÄìR721, doi: https://doi.org/10.1190/geo2019-0473.1.
Keating, S., and K. A. Innanen, 2020, Parameter crosstalk and leakage between spatially separated unknowns in viscoelastic full-waveform inversion
crosstalk analysis in viscoelastic FWI: Geophysics, 85, R397‚ÄìR408, doi: https://doi.org/10.1190/geo2019-0370.1.
Kingma, D. P., and J. Ba, 2014, Adam: A method for stochastic optimization: arXiv preprint arXiv:1412.6980.
K√∂hn, D., D. De Nil, A. Kurzmann, A. Przebindowska, and T. Bohlen, 2012, On the influence of model parametrization in elastic full waveform
tomography: Geophysical Journal International, 191, 325‚Äì345, doi: https://doi.org/10.1111/j.1365-246X.2012.05633.x.
Operto, S., Y. Gholami, V. Prieux, A. Ribodetti, R. Brossier, L. Metivier, and J. Virieux, 2013, A guided tour of multiparameter full-waveform
inversion with multicomponent data: From theory to practice: The Leading Edge, 32, 1040‚Äì1054, doi: https://doi.org/10.1190/tle32091040.1.
Pan, W., K. A. Innanen, Y. Geng, and J. Li, 2019, Interparameter trade-off quantification for isotropic-elastic full- waveform inversion with various
model parameterizations: Geophysics, 84, R185‚ÄìR206, doi: https://doi.org/10.1190/geo2017-0832.1.
Paszke, A., S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, and L. Antiga, 2019, Pytorch: An imperative style,
high-performance deep learning library: Advances in Neural Information Processing Systems, 32, doi: https://doi.org/10.48550/arXiv.1912.01703.
Tarantola, A., 1984, Inversion of seismic reflection data in the acoustic approximation: Geophysics, 49, 1259‚Äì1266, doi: https://doi.org/10.1190/1
.1441754.
Ulyanov, D., A. Vedaldi, and V. Lempitsky, 2018, Deep image prior: Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, 9446‚Äì9454.
Wang, W., G. A. McMechan, and J. Ma, 2021, Elastic isotropic and anisotropic full-waveform inversions using automatic differentiation for gradient
calculations in a framework of recurrent neural networks: Geophysics, 86, R795‚ÄìR810, doi: https://doi.org/10.1190/geo2020-0542.1.
Yang, F., and J. Ma, 2019, Deep-learning inversion: A next-generation seismic velocity model building method: Geophysics, 84, R583‚ÄìR599,
doi: https://doi.org/10.1190/geo2018-0249.1.
Zhang, T., J. Sun, K. A. Innanen, and D. Trad, 2021, Numerical analysis of a deep learning formulation of elastic full waveform inversion with high
order total variation regularization in different parameterization: arXiv preprint arXiv:2101.08924.
Zhu, W., K. Xu, E. Darve, B. Biondi, and G. C. Beroza, 2021, Integrating deep neural networks with full-waveform inversion: Reparametrization,
regularization, and uncertainty quantification: Geophysics, 87, 1‚Äì103, https://doi.org/doi:10.1190/geo2020-0933.1

Second International Meeting for Applied Geoscience & Energy
10.1190/image2022-3745050.1
Page 886
¬© 2022 Society of Exploration Geophysicists and the American Association of Petroleum Geologists

